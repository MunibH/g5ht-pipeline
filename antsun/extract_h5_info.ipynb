{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ad2d2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for: D:\\DATA\\g5ht-free\\20260123\\date-20260123_strain-ISg5HT-nsIS180_condition-fedpatch_worm004.h5\n",
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# set default matplotlib parameters for better aesthetics\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "# fontsize\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 13\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "\n",
    "# ============================================================\n",
    "# SET YOUR DATA PATH HERE\n",
    "# ============================================================\n",
    "# PTH = r'D:\\DATA\\g5ht-free\\20251223'\n",
    "# FN = 'date-20251223_strain-ISg5HT_condition-starvedpatch_worm005'  # without .h5 extension\n",
    "\n",
    "# PTH = r'D:\\DATA\\g5ht-free\\20251028'\n",
    "# FN = 'date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm002'  # without .h5 extension\n",
    "\n",
    "PTH = r'D:\\DATA\\g5ht-free\\20260123'\n",
    "FN = 'date-20260123_strain-ISg5HT-nsIS180_condition-fedpatch_worm004'  # without .h5 extension\n",
    "\n",
    "# PTH = r'D:\\DATA\\g5ht-free\\20251121'\n",
    "# FN = 'date-20251121_strain-ISg5HT_condition-fedpatch_worm001'\n",
    "\n",
    "# PTH = r'D:\\DATA\\g5ht-free\\20251106'\n",
    "# FN = 'date-20251106_strain-ISg5HT_condition-fedpatch_worm001'\n",
    "\n",
    "# PTH = r'D:\\DATA\\g5ht-free\\20260113'\n",
    "# FN = 'date-20260113_strain-ISg5HT-ADF-TeTx_condition-starvedpatch_worm004'\n",
    "\n",
    "# PTH = r'D:\\DATA\\g5ht-free\\20260114'\n",
    "# FN = 'date-20260114_strain-ISg5HT_condition-starvedpatch_worm001'\n",
    "\n",
    "h5_path = os.path.join(PTH, FN + '.h5')\n",
    "\n",
    "# Number of z-slices per confocal volume\n",
    "N_STACK = 41\n",
    "\n",
    "print(f\"Looking for: {h5_path}\")\n",
    "print(f\"File exists: {os.path.exists(h5_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7723e574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HDF5 file structure: D:\\DATA\\g5ht-free\\20260123\\date-20260123_strain-ISg5HT-nsIS180_condition-fedpatch_worm004.h5\n",
      "\n",
      "  daqmx_ai                                 shape=(3, 3269954)         dtype=float64\n",
      "  daqmx_di                                 shape=(2, 3269970)         dtype=uint32\n",
      "  img_metadata/  (group)\n",
      "  img_metadata/img_id                      shape=(25757,)             dtype=int64\n",
      "  img_metadata/img_timestamp               shape=(25757,)             dtype=int64\n",
      "  img_metadata/q_iter_save                 shape=(25757,)             dtype=uint8\n",
      "  img_metadata/q_recording                 shape=(25757,)             dtype=uint8\n",
      "  img_nir                                  shape=(12878, 732, 968)    dtype=uint8\n",
      "  pos_feature                              shape=(12878, 3, 3)        dtype=float32\n",
      "  pos_stage                                shape=(12878, 2)           dtype=float64\n",
      "  recording_start                          shape=()                   dtype=|S23\n",
      "\n",
      "--- Key Dataset Info ---\n",
      "  img_nir: (12878, 732, 968)  (n_frames=12878)\n",
      "  daqmx_ai: (3, 3269954)\n",
      "  daqmx_di: (2, 3269970)\n",
      "  img_metadata/img_id: (25757,)\n",
      "  img_metadata/img_timestamp: (25757,)\n",
      "  img_metadata/q_iter_save: (25757,)\n",
      "  img_metadata/q_recording: (25757,)\n"
     ]
    }
   ],
   "source": [
    "def print_h5_structure(h5_path):\n",
    "    \"\"\"Recursively print all datasets and groups in an HDF5 file.\"\"\"\n",
    "    def visitor(name, obj):\n",
    "        if isinstance(obj, h5py.Dataset):\n",
    "            print(f\"  {name:40s} shape={str(obj.shape):20s} dtype={obj.dtype}\")\n",
    "        elif isinstance(obj, h5py.Group):\n",
    "            print(f\"  {name}/  (group)\")\n",
    "\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        print(f\"\\nHDF5 file structure: {h5_path}\\n\")\n",
    "        f.visititems(visitor)\n",
    "        \n",
    "        # Key checks\n",
    "        print(\"\\n--- Key Dataset Info ---\")\n",
    "        if 'img_nir' in f:\n",
    "            shape = f['img_nir'].shape\n",
    "            print(f\"  img_nir: {shape}  (n_frames={shape[0] if len(shape)==3 else shape[2]})\")\n",
    "        else:\n",
    "            print(\"  ⚠ img_nir NOT FOUND\")\n",
    "            \n",
    "        if 'daqmx_ai' in f:\n",
    "            print(f\"  daqmx_ai: {f['daqmx_ai'].shape}\")\n",
    "        else:\n",
    "            print(\"  ⚠ daqmx_ai NOT FOUND\")\n",
    "            \n",
    "        if 'daqmx_di' in f:\n",
    "            print(f\"  daqmx_di: {f['daqmx_di'].shape}\")\n",
    "        else:\n",
    "            print(\"  ⚠ daqmx_di NOT FOUND\")\n",
    "            \n",
    "        if 'img_metadata' in f:\n",
    "            for key in f['img_metadata'].keys():\n",
    "                print(f\"  img_metadata/{key}: {f['img_metadata'][key].shape}\")\n",
    "        else:\n",
    "            print(\"  ⚠ img_metadata NOT FOUND\")\n",
    "\n",
    "print_h5_structure(h5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26432d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_stage shape: (12878, 2)\n",
      "Total frames: 12878\n",
      "Valid frames: 9654 (75.0%)\n",
      "Duration: 482.6 s (8.0 min)\n",
      "Mean speed: 0.0751 mm/s\n",
      "Total distance: 36.28 mm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "# --- Speed from pos_stage ---\n",
    "STAGE_UNIT = 10000\n",
    "\n",
    "# --- Time axis ---\n",
    "# Stage is saved on odd loop_count iterations at LOOP_INTERVAL_CONTROL=40 Hz\n",
    "# From loop_main: stage channel gets a put! on every odd iteration → ~20 Hz\n",
    "STAGE_SAVE_RATE = 20.0  # Hz (LOOP_INTERVAL_SAVE_STAGE from constant.jl)\n",
    "dt = 1.0 / STAGE_SAVE_RATE  # seconds per stage sample\n",
    "\n",
    "with h5py.File(h5_path, 'r') as f:\n",
    "    pos_stage = f['pos_stage'][:]  # saved as (2, n_t) from Julia\n",
    "\n",
    "# Julia saves as (2, n_t), h5py reads column-major, so check shape\n",
    "print(f\"pos_stage shape: {pos_stage.shape}\")\n",
    "\n",
    "# Ensure shape is (n_t, 2) — x,y columns\n",
    "if pos_stage.shape[0] == 2:\n",
    "    pos_stage = pos_stage.T  # now (n_t, 2)\n",
    "\n",
    "# --- Remove NaN frames (stage read errors set NaN in gui_loop.jl) ---\n",
    "valid = ~np.isnan(pos_stage).any(axis=1)\n",
    "pos_valid = pos_stage[valid]\n",
    "valid_idx = np.where(valid)[0]\n",
    "\n",
    "# --- Stage unit to mm conversion ---\n",
    "# From gui_loop.jl: covert_stage_unit_to_mm() is applied to stage values.\n",
    "# You need to set this to match your setup. Common Zaber/similar stages use\n",
    "# a microstep-to-mm factor. Check your Julia code for covert_stage_unit_to_mm.\n",
    "# Placeholder — REPLACE with your actual conversion:\n",
    "def convert_stage_unit_to_mm(val):\n",
    "    # e.g., for Zaber stages: 1 microstep = 0.047625 µm → 4.7625e-5 mm\n",
    "    # The /2 in read_position is already applied before saving\n",
    "    return val / STAGE_UNIT  # <-- REPLACE with your actual factor\n",
    "\n",
    "pos_mm = convert_stage_unit_to_mm(pos_valid)  # (n_valid, 2) in mm\n",
    "\n",
    "# --- Instantaneous speed (mm/s) ---\n",
    "# Mirrors gui_loop.jl:\n",
    "#   Δstage = norm(cb_last.val .- cb_first.val, 2)\n",
    "#   speed_worm_stage = Δstage / Δt_cb\n",
    "#   speed_worm_mm = covert_stage_unit_to_mm(speed_worm_stage)\n",
    "dx = np.diff(pos_mm, axis=0)  # (n-1, 2)\n",
    "displacement_mm = np.linalg.norm(dx, axis=1)  # Euclidean distance per step\n",
    "speed_mm_s = displacement_mm / dt  # mm/s\n",
    "\n",
    "# --- Smoothed speed (~1s window, matching speed_cb circular buffer) ---\n",
    "# gui_loop.jl uses a CircularBuffer of size ceil(Int, (1/20^-1)/2) = ceil(10) = 10\n",
    "# It computes speed as total displacement / total time over the buffer window\n",
    "window_size = 10  # ~0.5s at 20 Hz, matching the circular buffer size\n",
    "speed_smooth = np.convolve(speed_mm_s, np.ones(window_size) / window_size, mode='same')\n",
    "\n",
    "# --- Time axis for speed ---\n",
    "time_s = np.arange(len(speed_mm_s)) * dt\n",
    "\n",
    "# --- Plot ---\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8), gridspec_kw={'height_ratios': [2, 2, 1.5]})\n",
    "\n",
    "# Speed\n",
    "# axes[0].plot(time_s, speed_mm_s, alpha=0.3, color='gray', label='Instantaneous')\n",
    "axes[0].plot(time_s, speed_smooth, color='red', linewidth=2, label=f'Smoothed ({window_size}-sample avg)')\n",
    "axes[0].set_ylabel('Speed (mm/s)')\n",
    "axes[0].set_title('Worm Speed from Stage Position')\n",
    "axes[0].legend()\n",
    "\n",
    "# Cumulative displacement\n",
    "cumulative_dist = np.cumsum(displacement_mm)\n",
    "axes[1].plot(time_s, cumulative_dist, color='blue')\n",
    "axes[1].set_ylabel('Cumulative distance (mm)')\n",
    "axes[1].set_xlabel('Time (s)')\n",
    "\n",
    "# Trajectory\n",
    "axes[2].plot(pos_mm[:, 0], pos_mm[:, 1], linewidth=0.5, color='black')\n",
    "axes[2].set_xlabel('X (mm)')\n",
    "axes[2].set_ylabel('Y (mm)')\n",
    "axes[2].set_title('Stage Trajectory')\n",
    "axes[2].set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total frames: {pos_stage.shape[0]}\")\n",
    "print(f\"Valid frames: {pos_valid.shape[0]} ({100*pos_valid.shape[0]/pos_stage.shape[0]:.1f}%)\")\n",
    "print(f\"Duration: {time_s[-1]:.1f} s ({time_s[-1]/60:.1f} min)\")\n",
    "print(f\"Mean speed: {np.nanmean(speed_smooth):.4f} mm/s\")\n",
    "print(f\"Total distance: {cumulative_dist[-1]:.2f} mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd9237dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "daqmx_ai shape: (3, 3261997)\n",
      "daqmx_di shape: (2, 3262014)\n",
      "recording_start: b'2026-01-14T15:35:49.887'\n"
     ]
    }
   ],
   "source": [
    "# Quick visualization of the signals used for synchronization\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "lw = 2\n",
    "\n",
    "with h5py.File(h5_path, 'r') as f:\n",
    "    daqmx_ai = f['daqmx_ai'][:]\n",
    "    daqmx_di = f['daqmx_di'][:]\n",
    "    recording_start = f['recording_start'][()]\n",
    "\n",
    "n_index = daqmx_ai.shape[1]\n",
    "\n",
    "# for each signal, concatenate in time, the first N and the last N samples, to visualize the beginning and end of the recording in one plot\n",
    "# pad with NaNs in between to separate the two segments visually\n",
    "Npad_pre = 10000 # skip the first 10000 samples, which are very noisy and not useful for visualization\n",
    "Npre = 40000\n",
    "Npost = 100000\n",
    "Npad = 5000\n",
    "signal_segments_ai = []\n",
    "signal_segments_di = []\n",
    "for i in range(daqmx_ai.shape[0]):\n",
    "    signal = daqmx_ai[:, i] if daqmx_ai.shape[0] > daqmx_ai.shape[1] else daqmx_ai[i, :]\n",
    "    segment = np.concatenate((signal[Npad_pre:Npad_pre+Npre], np.full(Npad, np.nan), signal[-Npost:]))\n",
    "    signal_segments_ai.append(segment)\n",
    "for i in range(daqmx_di.shape[0]):\n",
    "    signal = daqmx_di[:, i] if daqmx_di.shape[0] > daqmx_di.shape[1] else daqmx_di[i, :]\n",
    "    segment = np.concatenate((signal[Npad_pre:Npad_pre+Npre], np.full(Npad, np.nan), signal[-Npost:]))\n",
    "    signal_segments_di.append(segment)\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(16, 14), sharex=True)\n",
    "\n",
    "labels = [\n",
    "    ('daqmx_ai col 0', 'Laser Signal', 'orange'),\n",
    "    ('daqmx_ai col 1', 'Piezo Signal', 'blue'),\n",
    "    ('daqmx_di col 0', 'Confocal Camera DI', 'green'),\n",
    "    ('daqmx_di col 1', 'NIR Camera DI', 'red'),\n",
    "]\n",
    "\n",
    "# plot the analog and digital signal segments\n",
    "for i in range(2):\n",
    "    axes[i].plot(signal_segments_ai[i], color=labels[i][2], linewidth=lw)\n",
    "    axes[i].set_ylabel(labels[i][1])\n",
    "    axes[i].set_title(labels[i][0])\n",
    "for i in range(2):\n",
    "    axes[i+2].plot(signal_segments_di[i], color=labels[i+2][2], linewidth=lw)\n",
    "    axes[i+2].set_ylabel(labels[i+2][1])\n",
    "    axes[i+2].set_title(labels[i+2][0])\n",
    "\n",
    "# # Plot analog inputs\n",
    "# for i in range(2):\n",
    "#     axes[i].plot(daqmx_ai[i, index2plot[0]:index2plot[1]] if daqmx_ai.shape[0] < daqmx_ai.shape[1] else daqmx_ai[index2plot[0]:index2plot[1], i],\n",
    "#                  color=labels[i][2], linewidth=lw)\n",
    "#     axes[i].set_ylabel(labels[i][1])\n",
    "#     axes[i].set_title(labels[i][0])\n",
    "\n",
    "# # Plot digital inputs\n",
    "# for i in range(2):\n",
    "#     axes[i+2].plot(daqmx_di[i, index2plot[0]:index2plot[1]] if daqmx_di.shape[0] < daqmx_di.shape[1] else daqmx_di[index2plot[0]:index2plot[1], i],\n",
    "#                    color=labels[i+2][2], linewidth=lw)\n",
    "#     axes[i+2].set_ylabel(labels[i+2][1])\n",
    "#     axes[i+2].set_title(labels[i+2][0])\n",
    "\n",
    "axes[-1].set_xlabel('Sample index')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\ndaqmx_ai shape: {daqmx_ai.shape}\")\n",
    "print(f\"daqmx_di shape: {daqmx_di.shape}\")\n",
    "print(f\"recording_start: {recording_start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb89b85",
   "metadata": {},
   "source": [
    "# V3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c56073",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65347b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'signal' is your numpy array \n",
    "# and 'peaks' is your array of peak indices\n",
    "def find_wave_starts(signal, peaks):\n",
    "    starts = []\n",
    "    \n",
    "    for i in range(len(peaks)):\n",
    "        if i == 0:\n",
    "            # For the first peak, search from the beginning of the signal\n",
    "            start_idx = np.argmin(signal[:peaks[i]])\n",
    "        else:\n",
    "            # Search between the previous peak and current peak\n",
    "            search_range = signal[peaks[i-1] : peaks[i]]\n",
    "            # Add the offset of the previous peak to get the absolute index\n",
    "            start_idx = np.argmin(search_range) + peaks[i-1]\n",
    "            \n",
    "        starts.append(start_idx)\n",
    "        \n",
    "    return np.array(starts)\n",
    "\n",
    "# Example usage:\n",
    "# start_indices = find_wave_starts(my_signal, peak_indices)\n",
    "\n",
    "def map_timestamps(source_timing, reference_timing):\n",
    "    \"\"\"\n",
    "    Finds which interval in reference_timing each source_start falls into.\n",
    "    Assumes reference_timing is sorted by start times.\n",
    "    \"\"\"\n",
    "    # Extract start times for binary search\n",
    "    ref_starts = reference_timing[:, 0]\n",
    "    ref_stops = reference_timing[:, 1]\n",
    "    source_starts = source_timing[:, 0]\n",
    "\n",
    "    # Find the index where each source_start would fit in ref_starts\n",
    "    # 'side=right' - 1 gives us the index j such that ref_starts[j] <= source_start\n",
    "    idx = np.searchsorted(ref_starts, source_starts, side='right') - 1\n",
    "\n",
    "    # Validation: Check if it actually falls within the [start, stop] window\n",
    "    # If the index is -1 or source_start > stop, it doesn't fit any interval\n",
    "    mask = (idx >= 0) & (source_starts <= ref_stops[idx])\n",
    "    \n",
    "    # Create result array (NaN for no match, 1-based indexing for matches)\n",
    "    result = np.full(source_starts.shape[0], np.nan)\n",
    "    result[mask] = idx[mask] + 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "def generate_consecutive_counts(arr):\n",
    "    # Ensure input is a numpy array\n",
    "    arr = np.asarray(arr)\n",
    "    \n",
    "    # Identify where the values change (the first element is always a change)\n",
    "    # np.diff returns an array of differences between consecutive elements\n",
    "    # We check where that difference is not zero\n",
    "    change_indices = np.where(arr[:-1] != arr[1:])[0] + 1\n",
    "    \n",
    "    # Create an array of zeros to store the result\n",
    "    res = np.zeros(len(arr), dtype=int)\n",
    "    \n",
    "    # The starting positions of each new group are at index 0 and \n",
    "    # all positions identified by change_indices\n",
    "    starts = np.concatenate(([0], change_indices))\n",
    "    \n",
    "    # For each group, we subtract the start index from the current index\n",
    "    # to get the running count: [0, 1, 2, ...]\n",
    "    for i in range(len(starts)):\n",
    "        start = starts[i]\n",
    "        end = starts[i+1] if i + 1 < len(starts) else len(arr)\n",
    "        res[start:end] = np.arange(end - start)\n",
    "        \n",
    "    return res\n",
    "\n",
    "# # Example usage:\n",
    "# arr = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 5, 5, 5, 5])\n",
    "# print(generate_consecutive_counts(arr))\n",
    "# # Output: [0 1 2 3 4 0 1 2 3 4 0 1 2 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e40abf",
   "metadata": {},
   "source": [
    "### Plot all DAQ signals together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c420924",
   "metadata": {},
   "source": [
    "session.list_cam_info contains img_metadata\n",
    "\n",
    "It's using spinnaker.jl, so it's probably time since hardware powered on (img_timestamp)\n",
    "and it's probably in nanoseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24d39cea",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m confocal_start_sample_ai = confocal_on_sample[\u001b[32m0\u001b[39m] \u001b[38;5;66;03m# get first rising edge, which should correspond to confocal recording start\u001b[39;00m\n\u001b[32m     33\u001b[39m confocal_off_sample = np.where(np.diff(ai_laser) < -\u001b[32m0.5\u001b[39m)[\u001b[32m0\u001b[39m] + \u001b[32m1\u001b[39m \u001b[38;5;66;03m# find falling edges (laser off)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m confocal_stop_sample_ai = \u001b[43mconfocal_off_sample\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# get second falling edge, which should correspond to confocal recording stop, first falling edge is at the beginning of the recording (see plots related to ai_laser)\u001b[39;00m\n\u001b[32m     36\u001b[39m peaks, properties = find_peaks(\n\u001b[32m     37\u001b[39m     ai_piezo, \n\u001b[32m     38\u001b[39m     distance=\u001b[32m100\u001b[39m,\n\u001b[32m     39\u001b[39m     prominence=\u001b[32m1.0\u001b[39m\n\u001b[32m     40\u001b[39m ) \u001b[38;5;66;03m# find peaks in piezo signal, which should correspond to stack acquisition. distance is set to 400 samples\u001b[39;00m\n\u001b[32m     41\u001b[39m stack_start_sample = peaks.copy() + \u001b[32m150\u001b[39m \u001b[38;5;66;03m# +20 for visualization only\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: index 1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "from scipy.signal import find_peaks\n",
    "%matplotlib qt\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "N_STACK = 41\n",
    "\n",
    "NIDAQ_SAMPLE_RATE_AI = 5000.0 # Hz\n",
    "CONTROL_NIR_FPS = 40.0\n",
    "SAVE_NIR_FPS = 20.0\n",
    "\n",
    "with h5py.File(h5_path, 'r') as f:\n",
    "    daqmx_ai = f['daqmx_ai'][:]\n",
    "    daqmx_di = f['daqmx_di'][:]\n",
    "    n_img_nir = f['img_nir'].shape[0]\n",
    "    img_metadata = f['img_metadata']\n",
    "    img_timestamp = img_metadata['img_timestamp'][:]\n",
    "    img_id = img_metadata[\"img_id\"][:]\n",
    "    q_iter_save = img_metadata[\"q_iter_save\"][:]\n",
    "\n",
    "\n",
    "di_confocal = daqmx_di[0,:].astype(np.float32)\n",
    "di_nir = daqmx_di[1,:].astype(np.float32)\n",
    "ai_laser = daqmx_ai[0,:].astype(np.float32)\n",
    "ai_piezo = daqmx_ai[1,:].astype(np.float32)\n",
    "# ai_stim = daqmx_ai[2,:].astype(np.float32)\n",
    "img_timestamp_sec = (img_timestamp - img_timestamp[0]) / 1e9\n",
    "\n",
    "di_confocal_rise = np.where(np.diff(di_confocal) > 0.0)[0] + 1\n",
    "\n",
    "confocal_on_sample = np.where(np.diff(ai_laser) > 0.5)[0] + 1 # find rising edges (laser on)\n",
    "confocal_start_sample_ai = confocal_on_sample[0] # get first rising edge, which should correspond to confocal recording start\n",
    "confocal_off_sample = np.where(np.diff(ai_laser) < -0.5)[0] + 1 # find falling edges (laser off)\n",
    "confocal_stop_sample_ai = confocal_off_sample[1] # get second falling edge, which should correspond to confocal recording stop, first falling edge is at the beginning of the recording (see plots related to ai_laser)\n",
    "\n",
    "peaks, properties = find_peaks(\n",
    "    ai_piezo, \n",
    "    distance=100,\n",
    "    prominence=1.0\n",
    ") # find peaks in piezo signal, which should correspond to stack acquisition. distance is set to 400 samples\n",
    "stack_start_sample = peaks.copy() + 150 # +20 for visualization only\n",
    "stack_start_sample = np.insert(stack_start_sample, 0, confocal_start_sample_ai)  # prepend first element as confocal recording start\n",
    "stack_start_sample = stack_start_sample[:-1]  # delete last element\n",
    "\n",
    "stack_stop_sample = peaks.copy()\n",
    "stack_stop_sample[-1] = confocal_stop_sample_ai # set last stack stop to confocal recording stop\n",
    "piezo_timing = np.concatenate((stack_start_sample.reshape(-1,1), stack_stop_sample.reshape(-1,1)), axis=1) # combine piezo start and stop indices to get confocal stack timing\n",
    "\n",
    "# zoom = (0, 60000)\n",
    "# zoom = (3257743-100000,3257743)\n",
    "zoom = (0, len(ai_laser)-1)\n",
    "\n",
    "time = np.arange(len(ai_laser)) / NIDAQ_SAMPLE_RATE_AI\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(15,6), sharex=True)\n",
    "axs[0].plot(time[zoom[0]:zoom[1]], ai_laser[zoom[0]:zoom[1]], label='Laser Signal', color='orange')\n",
    "axs[1].plot(time[zoom[0]:zoom[1]], ai_piezo[zoom[0]:zoom[1]], label='Piezo Signal', color='blue')\n",
    "axs[2].plot(time[zoom[0]:zoom[1]], di_confocal[zoom[0]:zoom[1]], label='Confocal Camera DI', color='green')\n",
    "axs[3].plot(time[zoom[0]:zoom[1]], di_nir[zoom[0]:zoom[1]], label='NIR Camera DI', color='magenta')\n",
    "\n",
    "# plot every 41st di_confocal_rise index as vertical lines to see if they align with confocal stack timing\n",
    "# this is the start of the next confocal stack\n",
    "for idx in di_confocal_rise[::41]:\n",
    "    if zoom[0] <= idx < zoom[1]:\n",
    "        axs[2].axvline(x=time[idx]-time[zoom[0]], color='black', linestyle='-')\n",
    "\n",
    "# plot confocal recording start and stop\n",
    "axs[0].axvline(x=time[confocal_start_sample_ai]-time[zoom[0]], color='black', linestyle='--')\n",
    "axs[0].axvline(x=time[confocal_stop_sample_ai]-time[zoom[0]], color='black', linestyle='--')\n",
    "\n",
    "# plot stack start and stops as vertical lines to see if they align with confocal stack timing\n",
    "for (start,stop) in zip(piezo_timing[:,0], piezo_timing[:,1]):\n",
    "    if zoom[0] <= start < zoom[1]:\n",
    "        axs[1].axvline(x=time[start]-time[zoom[0]], color='green', linestyle='-')\n",
    "    if zoom[0] <= stop < zoom[1]:\n",
    "        axs[1].axvline(x=time[stop]-time[zoom[0]], color='red', linestyle='-')\n",
    "\n",
    "plt.xlim(0, time[zoom[1]]-time[zoom[0]])\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a21da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "%matplotlib qt\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "N_STACK = 41\n",
    "\n",
    "NIDAQ_SAMPLE_RATE_AI = 5000.0 # Hz\n",
    "CONTROL_NIR_FPS = 40.0\n",
    "SAVE_NIR_FPS = 20.0\n",
    "\n",
    "with h5py.File(h5_path, 'r') as f:\n",
    "    daqmx_ai = f['daqmx_ai'][:]\n",
    "    daqmx_di = f['daqmx_di'][:]\n",
    "    n_img_nir = f['img_nir'].shape[0]\n",
    "    img_metadata = f['img_metadata']\n",
    "    img_timestamp = img_metadata['img_timestamp'][:]\n",
    "    img_id = img_metadata[\"img_id\"][:]\n",
    "    q_iter_save = img_metadata[\"q_iter_save\"][:]\n",
    "\n",
    "\n",
    "di_confocal = daqmx_di[0,:].astype(np.float32)\n",
    "di_nir = daqmx_di[1,:].astype(np.float32)\n",
    "ai_laser = daqmx_ai[0,:].astype(np.float32)\n",
    "ai_piezo = daqmx_ai[1,:].astype(np.float32)\n",
    "# ai_stim = daqmx_ai[2,:].astype(np.float32)\n",
    "\n",
    "di_confocal_rise = np.where(np.diff(di_confocal) > 0.0)[0] + 1\n",
    "\n",
    "confocal_on_sample = np.where(np.diff(ai_laser) > 0.5)[0] + 1 # find rising edges (laser on)\n",
    "confocal_start_sample_ai = confocal_on_sample[0] # get first rising edge, which should correspond to confocal recording start\n",
    "confocal_off_sample = np.where(np.diff(ai_laser) < -0.5)[0] + 1 # find falling edges (laser off)\n",
    "confocal_stop_sample_ai = confocal_off_sample[1] # get second falling edge, which should correspond to confocal recording stop, first falling edge is at the beginning of the recording (see plots related to ai_laser)\n",
    "\n",
    "peaks, properties = find_peaks(\n",
    "    ai_piezo, \n",
    "    distance=100,\n",
    "    prominence=1.0\n",
    ") # find peaks in piezo signal, which should correspond to stack acquisition. distance is set to 400 samples\n",
    "stack_start_sample = peaks.copy() + 150 # +20 for visualization only\n",
    "stack_start_sample = np.insert(stack_start_sample, 0, confocal_start_sample_ai)  # prepend first element as confocal recording start\n",
    "stack_start_sample = stack_start_sample[:-1]  # delete last element\n",
    "\n",
    "stack_stop_sample = peaks.copy()\n",
    "stack_stop_sample[-1] = confocal_stop_sample_ai # set last stack stop to confocal recording stop\n",
    "piezo_timing = np.concatenate((stack_start_sample.reshape(-1,1), stack_stop_sample.reshape(-1,1)), axis=1) # combine piezo start and stop indices to get confocal stack timing\n",
    "\n",
    "# zoom = (0, 60000)\n",
    "# zoom = (3257743-100000,3257743)\n",
    "zoom = (0, len(ai_laser))\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(15,6), sharex=True)\n",
    "axs[0].plot(ai_laser[zoom[0]:zoom[1]], label='Laser Signal', color='orange')\n",
    "axs[1].plot(ai_piezo[zoom[0]:zoom[1]], label='Piezo Signal', color='blue')\n",
    "axs[2].plot(di_confocal[zoom[0]:zoom[1]], label='Confocal Camera DI', color='green')\n",
    "axs[3].plot(di_nir[zoom[0]:zoom[1]], label='NIR Camera DI', color='magenta')\n",
    "\n",
    "# plot every 41st di_confocal_rise index as vertical lines to see if they align with confocal stack timing\n",
    "# this is the start of the next confocal stack\n",
    "for idx in di_confocal_rise[::41]:\n",
    "    if zoom[0] <= idx < zoom[1]:\n",
    "        axs[2].axvline(x=idx-zoom[0], color='black', linestyle='-')\n",
    "\n",
    "# plot confocal recording start and stop\n",
    "axs[0].axvline(x=confocal_start_sample_ai-zoom[0], color='black', linestyle='--')\n",
    "axs[0].axvline(x=confocal_stop_sample_ai-zoom[0], color='black', linestyle='--')\n",
    "\n",
    "# plot stack start and stops as vertical lines to see if they align with confocal stack timing\n",
    "for (start,stop) in zip(piezo_timing[:,0], piezo_timing[:,1]):\n",
    "    if zoom[0] <= start < zoom[1]:\n",
    "        axs[1].axvline(x=start-zoom[0], color='green', linestyle='-')\n",
    "    if zoom[0] <= stop < zoom[1]:\n",
    "        axs[1].axvline(x=stop-zoom[0], color='red', linestyle='-')\n",
    "\n",
    "plt.xlim(0, zoom[1]-zoom[0])\n",
    "plt.xlabel('Sample index')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ec07f0",
   "metadata": {},
   "source": [
    "### AI Confocal plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea419b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "from scipy.stats import mode\n",
    "from sync import detect_nir_timing\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "with h5py.File(h5_path, 'r') as f:\n",
    "    ai_laser = f['daqmx_ai'][:][0,:].astype(np.float32)\n",
    "\n",
    "# get confocal recording start and stop times\n",
    "#   when ai_laser goes from 0 to 1, recording on\n",
    "#   when ai_laser goes from 1 to 0, recording off\n",
    "#   note: there is additional on/off signlas after recording off in ai_laser, this corresponds to nir recording, not getting those timestamps\n",
    "confocal_on_sample = np.where(np.diff(ai_laser) > 0.5)[0] + 1 # find rising edges (laser on)\n",
    "confocal_on_sample = confocal_on_sample[0] # get first rising edge, which should correspond to confocal recording start\n",
    "confocal_off_sample = np.where(np.diff(ai_laser) < -0.5)[0] + 1 # find falling edges (laser off)\n",
    "confocal_off_sample = confocal_off_sample[1] # get second falling edge, which should correspond to confocal recording stop, first falling edge is at the beginning of the recording (see plots related to ai_laser)\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(11, 4), sharex=True)\n",
    "axs[0].plot(ai_laser, label='AI confocal (Start)', color='orange')\n",
    "axs[0].plot(confocal_on_sample, ai_laser[confocal_on_sample], 'go', label='Confocal On')\n",
    "axs[0].plot(confocal_off_sample, ai_laser[confocal_off_sample], 'ro', label='Confocal Off')\n",
    "axs[0].legend()\n",
    "axs[1].plot(np.diff(ai_laser))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1527a460",
   "metadata": {},
   "source": [
    "### DI Confocal plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82e82bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\munib\\anaconda3\\envs\\imgpro\\Lib\\site-packages\\ipykernel\\eventloops.py:145: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  el.exec() if hasattr(el, \"exec\") else el.exec_()\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(h5_path, 'r') as f:\n",
    "    di_confocal = f['daqmx_di'][:][0,:].astype(np.float32)\n",
    "\n",
    "# get stack start (rise) and stop (fall) indices from di_confocal , which is the digital input from the confocal camera that should indicate when each stack starts and stops.\n",
    "di_confocal_rise = np.where(np.diff(di_confocal) > 0.0)[0] + 1\n",
    "di_confocal_fall = np.where(np.diff(di_confocal) < 0.0)[0] + 1\n",
    "confocal_start_sample_di = di_confocal_rise[0] # recording start in confocal\n",
    "confocal_timing = np.concatenate((di_confocal_rise.reshape(-1,1), di_confocal_fall.reshape(-1,1)), axis=1) # combine confocal rise and fall indices to get confocal stack timing\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(11, 4), sharex=True)\n",
    "axs[0].plot(di_confocal, label='DI confocal', color='orange')\n",
    "axs[0].plot(confocal_start_sample_di, di_confocal[confocal_start_sample_di], 'go', label='Confocal On')\n",
    "axs[0].legend()\n",
    "axs[1].plot(np.diff(di_confocal))\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(11, 4), sharex=True)\n",
    "axs[0].plot(di_confocal, label='DI confocal', color='orange')\n",
    "axs[0].plot(di_confocal_rise, di_confocal[di_confocal_rise], 'go', label='Confocal Stack Start')\n",
    "axs[0].plot(di_confocal_fall, di_confocal[di_confocal_fall], 'ro', label='Confocal Stack Stop')\n",
    "axs[0].legend()\n",
    "axs[1].plot(np.diff(di_confocal))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dddc463",
   "metadata": {},
   "source": [
    "### DI NIR plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0244db40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triggers detected (raw): 25947\n",
      "Total expected from img_id:     25966\n",
      "Mismatch:                       -19\n",
      "Saved frames (n_img_nir):       12780\n",
      "Sum of q_iter_save:             12780\n",
      "\n",
      "Large gaps (>500 samples) at indices: [25945]\n",
      "Gap sizes: [3803]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "N_STACK = 41\n",
    "\n",
    "NIDAQ_SAMPLE_RATE_AI = 5000.0 # Hz\n",
    "CONTROL_NIR_FPS = 40.0\n",
    "SAVE_NIR_FPS = 20.0\n",
    "\n",
    "with h5py.File(h5_path, 'r') as f:\n",
    "    daqmx_ai = f['daqmx_ai'][:]\n",
    "    daqmx_di = f['daqmx_di'][:]\n",
    "    n_img_nir = f['img_nir'].shape[0]\n",
    "    img_metadata = f['img_metadata']\n",
    "    img_timestamp = img_metadata['img_timestamp'][:]\n",
    "    img_id = img_metadata[\"img_id\"][:]\n",
    "    q_iter_save = img_metadata[\"q_iter_save\"][:]\n",
    "\n",
    "\n",
    "di_confocal = daqmx_di[0,:].astype(np.float32)\n",
    "di_nir = daqmx_di[1,:].astype(np.float32)\n",
    "ai_laser = daqmx_ai[0,:].astype(np.float32)\n",
    "ai_piezo = daqmx_ai[1,:].astype(np.float32)\n",
    "# ai_stim = daqmx_ai[2,:].astype(np.float32)\n",
    "img_timestamp_sec = (img_timestamp - img_timestamp[0]) / 1e9\n",
    "\n",
    "list_nir_on  = np.where(np.diff(di_nir) >  1)[0] + 1\n",
    "list_nir_off = np.where(np.diff(di_nir) < -1)[0] + 1\n",
    "\n",
    "total_expected = int(np.sum(np.diff(img_id)))\n",
    "\n",
    "print(f\"Total triggers detected (raw): {len(list_nir_on)}\")\n",
    "print(f\"Total expected from img_id:     {total_expected}\")\n",
    "print(f\"Mismatch:                       {len(list_nir_on) - total_expected}\")\n",
    "print(f\"Saved frames (n_img_nir):       {n_img_nir}\")\n",
    "print(f\"Sum of q_iter_save:             {np.sum(q_iter_save)}\")\n",
    "\n",
    "# Check the recording window detection\n",
    "gaps = np.diff(list_nir_on)\n",
    "large_gaps = np.where(gaps > 500)[0]\n",
    "print(f\"\\nLarge gaps (>500 samples) at indices: {large_gaps}\")\n",
    "print(f\"Gap sizes: {gaps[large_gaps]}\")\n",
    "\n",
    "# Plot to visually inspect\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(di_nir, color='magenta')\n",
    "for g in large_gaps:\n",
    "    plt.axvline(list_nir_on[g], color='red', linestyle='--', alpha=0.7)\n",
    "    plt.axvline(list_nir_on[g+1], color='green', linestyle='--', alpha=0.7)\n",
    "plt.title('NIR digital signal with large gaps marked')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18de4a52",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     35\u001b[39m confocal_recording_start     = confocal_on_sample[\u001b[32m0\u001b[39m]\n\u001b[32m     36\u001b[39m confocal_off_sample = np.where(np.diff(ai_laser) < -\u001b[32m0.5\u001b[39m)[\u001b[32m0\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m confocal_recording_stop      = \u001b[43mconfocal_off_sample\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Find all trigger edges\u001b[39;00m\n\u001b[32m     41\u001b[39m list_nir_on  = np.where(np.diff(di_nir) >  \u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m] + \u001b[32m1\u001b[39m\n",
      "\u001b[31mIndexError\u001b[39m: index 1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# isolated detect nir timing code for testing\n",
    "%matplotlib qt\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "_ = importlib.reload(sys.modules['sync'])\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "N_STACK = 41\n",
    "\n",
    "NIDAQ_SAMPLE_RATE_AI = 5000.0 # Hz\n",
    "CONTROL_NIR_FPS = 40.0\n",
    "SAVE_NIR_FPS = 20.0\n",
    "\n",
    "with h5py.File(h5_path, 'r') as f:\n",
    "    daqmx_ai = f['daqmx_ai'][:]\n",
    "    daqmx_di = f['daqmx_di'][:]\n",
    "    n_img_nir = f['img_nir'].shape[0]\n",
    "    img_metadata = f['img_metadata']\n",
    "    img_timestamp = img_metadata['img_timestamp'][:]\n",
    "    img_id = img_metadata[\"img_id\"][:]\n",
    "    q_iter_save = img_metadata[\"q_iter_save\"][:]\n",
    "\n",
    "\n",
    "di_confocal = daqmx_di[0,:].astype(np.float32)\n",
    "di_nir = daqmx_di[1,:].astype(np.float32)\n",
    "ai_laser = daqmx_ai[0,:].astype(np.float32)\n",
    "ai_piezo = daqmx_ai[1,:].astype(np.float32)\n",
    "# ai_stim = daqmx_ai[2,:].astype(np.float32)\n",
    "img_timestamp_sec = (img_timestamp - img_timestamp[0]) / 1e9\n",
    "\n",
    "# Get recording window from ai_laser (your existing logic)\n",
    "confocal_on_sample  = np.where(np.diff(ai_laser) > 0.5)[0] + 1\n",
    "confocal_recording_start     = confocal_on_sample[0]\n",
    "confocal_off_sample = np.where(np.diff(ai_laser) < -0.5)[0] + 1\n",
    "confocal_recording_stop      = confocal_off_sample[1]\n",
    "\n",
    "\n",
    "# Find all trigger edges\n",
    "list_nir_on  = np.where(np.diff(di_nir) >  1)[0] + 1\n",
    "list_nir_off = np.where(np.diff(di_nir) < -1)[0] + 1\n",
    "\n",
    "nir_record_on  = np.diff(list_nir_on)  > 500\n",
    "nir_record_off = np.diff(list_nir_off) > 500\n",
    "\n",
    "# --- recording start ---\n",
    "if list_nir_on[0] > 500:\n",
    "    s_nir_start = list_nir_on[0]\n",
    "elif np.sum(nir_record_on) == 2:\n",
    "    s_nir_start = list_nir_on[np.where(nir_record_on)[0][0] + 1]\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"More than 2 recording-on transitions detected for FLIR camera\"\n",
    "    )\n",
    "\n",
    "# --- recording stop ---\n",
    "if list_nir_off[-1] < len(di_nir) - 500:\n",
    "    s_nir_stop = list_nir_off[-1]\n",
    "elif np.sum(nir_record_off) <= 2:\n",
    "    s_nir_stop = list_nir_off[\n",
    "        np.where(np.diff(list_nir_off) > 500)[0][-1]\n",
    "    ]\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"More than 2 recording-off transitions detected for FLIR camera\"\n",
    "    )\n",
    "    \n",
    "# Keep triggers inside the recording window (±5 samples tolerance)\n",
    "mask_on  = (s_nir_start - 5 < list_nir_on)  & (list_nir_on  < s_nir_stop + 5)\n",
    "mask_off = (s_nir_start - 5 < list_nir_off) & (list_nir_off < s_nir_stop + 5)\n",
    "list_nir_on  = list_nir_on[mask_on]\n",
    "list_nir_off = list_nir_off[mask_off]\n",
    "\n",
    "# looks good so far\n",
    "\n",
    "img_id_diff = np.diff(img_id).tolist() # img_id_diff , how many camera triggers happened between consecutive iterations. Usually 1, if >1, that means triggers fired but were not saved (frame skips)\n",
    "img_id_diff.insert(0, 1)\n",
    "total_expected = int(np.sum(np.diff(img_id)))\n",
    "\n",
    "if abs(len(list_nir_on) - total_expected) > 3:\n",
    "    raise ValueError(\n",
    "        f\"Detected trigger count ({len(list_nir_on)}) differs from \"\n",
    "        f\"image-ID count ({total_expected}) by more than 3\"\n",
    "    )\n",
    "else:\n",
    "    img_id_diff[-1] += len(list_nir_on) - total_expected - 1\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(di_nir, label='DI NIR', color='magenta')\n",
    "plt.plot(list_nir_on, di_nir[list_nir_on], 'go', label='NIR On')\n",
    "plt.plot(list_nir_off, di_nir[list_nir_off], 'ro', label='NIR Off')\n",
    "plt.axvline(confocal_recording_start, color='blue', linestyle='--', label='Confocal Recording Start')\n",
    "plt.axvline(confocal_recording_stop, color='red', linestyle='--', label='Confocal Recording Stop')\n",
    "# plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba4653c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot number of samples between saved nir frames\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(np.diff(img_timestamp[q_iter_save.astype(bool)]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45378311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot di nir with img timestamps\n",
    "%matplotlib qt\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "N_STACK = 41\n",
    "\n",
    "NIDAQ_SAMPLE_RATE_AI = 5000.0 # Hz\n",
    "CONTROL_NIR_FPS = 40.0\n",
    "SAVE_NIR_FPS = 20.0\n",
    "\n",
    "with h5py.File(h5_path, 'r') as f:\n",
    "    daqmx_ai = f['daqmx_ai'][:]\n",
    "    daqmx_di = f['daqmx_di'][:]\n",
    "    n_img_nir = f['img_nir'].shape[0]\n",
    "    img_metadata = f['img_metadata']\n",
    "    img_timestamp = img_metadata['img_timestamp'][:]\n",
    "    img_id = img_metadata[\"img_id\"][:]\n",
    "    q_iter_save = img_metadata[\"q_iter_save\"][:]\n",
    "\n",
    "\n",
    "di_confocal = daqmx_di[0,:].astype(np.float32)\n",
    "di_nir = daqmx_di[1,:].astype(np.float32)\n",
    "ai_laser = daqmx_ai[0,:].astype(np.float32)\n",
    "ai_piezo = daqmx_ai[1,:].astype(np.float32)\n",
    "# ai_stim = daqmx_ai[2,:].astype(np.float32)\n",
    "\n",
    "# Find all trigger edges\n",
    "list_nir_on  = np.where(np.diff(di_nir) >  1)[0] + 1\n",
    "list_nir_off = np.where(np.diff(di_nir) < -1)[0] + 1\n",
    "\n",
    "nir_record_on  = np.diff(list_nir_on)  > 500\n",
    "nir_record_off = np.diff(list_nir_off) > 500\n",
    "\n",
    "# --- recording start ---\n",
    "if list_nir_on[0] > 500:\n",
    "    s_nir_start = list_nir_on[0]\n",
    "elif np.sum(nir_record_on) == 2:\n",
    "    s_nir_start = list_nir_on[np.where(nir_record_on)[0][0] + 1]\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"More than 2 recording-on transitions detected for FLIR camera\"\n",
    "    )\n",
    "\n",
    "# --- recording stop ---\n",
    "if list_nir_off[-1] < len(di_nir) - 500:\n",
    "    s_nir_stop = list_nir_off[-1]\n",
    "elif np.sum(nir_record_off) <= 2:\n",
    "    s_nir_stop = list_nir_off[\n",
    "        np.where(np.diff(list_nir_off) > 500)[0][-1]\n",
    "    ]\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"More than 2 recording-off transitions detected for FLIR camera\"\n",
    "    )\n",
    "    \n",
    "# Keep triggers inside the recording window (±5 samples tolerance)\n",
    "mask_on  = (s_nir_start - 5 < list_nir_on)  & (list_nir_on  < s_nir_stop + 5)\n",
    "mask_off = (s_nir_start - 5 < list_nir_off) & (list_nir_off < s_nir_stop + 5)\n",
    "list_nir_on  = list_nir_on[mask_on]\n",
    "list_nir_off = list_nir_off[mask_off]\n",
    "\n",
    "\n",
    "\n",
    "img_timestamp_sec = (img_timestamp - img_timestamp[0]) / 1e9 + (list_nir_on[0]/NIDAQ_SAMPLE_RATE_AI) # 0.1617 #+ 0.1798\n",
    "\n",
    "img_timestamp_sec_saved = img_timestamp_sec[q_iter_save.astype(bool)]\n",
    "\n",
    "time = np.arange(len(di_nir)) / NIDAQ_SAMPLE_RATE_AI\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(time, di_nir, label='DI NIR', color='magenta')\n",
    "# plot vertical lines for img_timestamp_sec\n",
    "for ts in img_timestamp_sec_saved:\n",
    "    plt.axvline(ts, color='black', linestyle='-', alpha=1.0)\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('DI NIR')\n",
    "plt.title('NIR Digital Signal with Image Timestamps')\n",
    "# plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fecc84",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9721f4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded daqmx_ai with shape: (4, 619244)\n",
      "Loaded daqmx_di with shape: (2, 619260)\n",
      "img_id with shape: (4825,)\n",
      "img_timestamp with shape: (4825,)\n",
      "q_iter_save with shape: (4825,)\n",
      "Number of NIR images: 2412\n"
     ]
    }
   ],
   "source": [
    "# main code\n",
    "\n",
    "from scipy.stats import mode\n",
    "from sync import detect_nir_timing\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "N_STACK = 41\n",
    "\n",
    "NIDAQ_SAMPLE_RATE_AI = 5000.0 # Hz\n",
    "CONTROL_NIR_FPS = 40.0\n",
    "SAVE_NIR_FPS = 20.0\n",
    "\n",
    "\n",
    "with h5py.File(h5_path, 'r') as f:\n",
    "    daqmx_ai = f['daqmx_ai'][:]\n",
    "    daqmx_di = f['daqmx_di'][:]\n",
    "    n_img_nir = f['img_nir'].shape[0]\n",
    "    img_metadata = f['img_metadata']\n",
    "    img_timestamp = img_metadata['img_timestamp'][:]\n",
    "    img_id = img_metadata[\"img_id\"][:]\n",
    "    q_iter_save = img_metadata[\"q_iter_save\"][:]\n",
    "        \n",
    "print(f\"Loaded daqmx_ai with shape: {daqmx_ai.shape}\")\n",
    "print(f\"Loaded daqmx_di with shape: {daqmx_di.shape}\")\n",
    "print(f\"img_id with shape: {img_id.shape}\")\n",
    "print(f\"img_timestamp with shape: {img_timestamp.shape}\")\n",
    "print(f\"q_iter_save with shape: {q_iter_save.shape}\")\n",
    "print(f\"Number of NIR images: {n_img_nir}\")\n",
    "\n",
    "di_confocal = daqmx_di[0,:].astype(np.float32)\n",
    "di_nir = daqmx_di[1,:].astype(np.float32)\n",
    "ai_laser = daqmx_ai[0,:].astype(np.float32)\n",
    "ai_piezo = daqmx_ai[1,:].astype(np.float32)\n",
    "\n",
    "\n",
    "# # get confocal recording start and stop times\n",
    "# #   when ai_laser goes from 0 to 1, recording on\n",
    "# #   when ai_laser goes from 1 to 0, recording off\n",
    "# #   note: there is additional on/off signlas after recording off in ai_laser, this corresponds to nir recording, not getting those timestamps\n",
    "# confocal_on_sample = np.where(np.diff(ai_laser) > 0.5)[0] + 1 # find rising edges (laser on)\n",
    "# confocal_start_sample_ai = confocal_on_sample[0] # get first rising edge, which should correspond to confocal recording start\n",
    "# confocal_off_sample = np.where(np.diff(ai_laser) < -0.5)[0] + 1 # find falling edges (laser off)\n",
    "# confocal_stop_sample_ai = confocal_off_sample[1] # get second falling edge, which should correspond to confocal recording stop, first falling edge is at the beginning of the recording (see plots related to ai_laser)\n",
    "\n",
    "# get stack start (rise) and stop (fall) indices from di_confocal , which is the digital input from the confocal camera that should indicate when each stack starts and stops.\n",
    "di_confocal_rise = np.where(np.diff(di_confocal) > 0.0)[0] + 1\n",
    "di_confocal_fall = np.where(np.diff(di_confocal) < 0.0)[0] + 1\n",
    "confocal_start_sample_di = di_confocal_rise[0] # recording start in confocal\n",
    "confocal_stop_sample_di = di_confocal_fall[-1] # recording stop in confocal, should be the last falling edge\n",
    "confocal_timing = np.concatenate((di_confocal_rise.reshape(-1,1), di_confocal_fall.reshape(-1,1)), axis=1) # combine confocal rise and fall indices to get confocal stack timing\n",
    "\n",
    "# # confocal_start_idx from di should be the same as confocal_start_idx from ai_laser, which is what we were using before. let's check that.\n",
    "# assert (confocal_start_sample_ai - confocal_start_sample_di) == 0, \"Confocal start index from DI and AI do not match\"\n",
    "\n",
    "# find piezo start stop (fall) times from ai_piezo. ai_piezo is a ramping signal that indicates when the piezo is moving, which should correspond to when the confocal camera is acquiring a stack. we can use this to check if the confocal stack timing from di_confocal matches the piezo movement timing from ai_piezo.\n",
    "# need to first find the peaks using a peak finding algorithm, since the piezo signal is not a perfect ramp and has some noise. we can use scipy.signal.find_peaks for this.\n",
    "peaks, properties = find_peaks(\n",
    "    ai_piezo, \n",
    "    distance=100,\n",
    "    prominence=1.0\n",
    ") # find peaks in piezo signal, which should correspond to stack acquisition. distance is set to 400 samples\n",
    "stack_start_sample = peaks.copy()\n",
    "stack_start_sample = np.insert(stack_start_sample, 0, confocal_start_sample_di)  # prepend first element as confocal recording start\n",
    "stack_start_sample = stack_start_sample[:-1]  # delete last element\n",
    "\n",
    "stack_stop_sample = peaks.copy()\n",
    "stack_stop_sample[-1] = confocal_stop_sample_di # set last stack stop to confocal recording stop\n",
    "piezo_timing = np.concatenate((stack_start_sample.reshape(-1,1), stack_stop_sample.reshape(-1,1)), axis=1) # combine piezo start and stop indices to get confocal stack timing\n",
    "\n",
    "\n",
    "# get nir recording start (rise) and stop (fall) indices from di_nir, which is the digital input from the NIR camera that should indicate when each NIR recording starts and stops.\n",
    "nir_timing = detect_nir_timing(di_nir, img_id, q_iter_save, n_img_nir)\n",
    "di_nir_rise = nir_timing[:, 0]\n",
    "di_nir_fall = nir_timing[:, 1]\n",
    "# di_nir_rise = np.where(np.diff(di_nir) > 0.5)[0]\n",
    "# di_nir_fall = np.where(np.diff(di_nir) < -0.5)[0]\n",
    "nir_start_idx = di_nir_rise[0] # recording start in NIR\n",
    "\n",
    "# validated this with working recording, that passed detect_nir_timing's checks\n",
    "# for recordings that don't pass, might have to trim out some img_timstamps at end of recording that seem to be artifacts, but not totally sure\n",
    "img_timestamp_sec = (img_timestamp - img_timestamp[0]) / 1e9 + (nir_start_idx/NIDAQ_SAMPLE_RATE_AI)\n",
    "img_timestamp_sec_saved = img_timestamp_sec[q_iter_save.astype(bool)]\n",
    "\n",
    "\n",
    "# # we have confocal_timing, piezo_timing, nir_timing\n",
    "# let's  now map them\n",
    "\n",
    "# 1. Confocal to Piezo mapping (which confocal stack corresponds each di_confocal corresonds to)\n",
    "confocal_to_piezo_mapping = map_timestamps(confocal_timing, piezo_timing)\n",
    "\n",
    "# 2. NIR to Piezo mapping (which confocal stack corresponds to each nir frame)\n",
    "nir_to_piezo_mapping = map_timestamps(nir_timing, piezo_timing)\n",
    "\n",
    "# 3. NIR to Confocal mapping ()\n",
    "nir_to_confocal_mapping = map_timestamps(nir_timing, confocal_timing)\n",
    "\n",
    "# 4. Plane number \n",
    "confocal_plane = generate_consecutive_counts(confocal_to_piezo_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "360ad992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot everything\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(15,6), sharex=True)\n",
    "axs[0].plot(ai_laser, label='Laser Signal', color='orange')\n",
    "# plot laser signal start idx\n",
    "axs[0].plot(confocal_start_sample_di, ai_laser[confocal_start_sample_di], 'o', label='Confocal Start (DI)', color='red')\n",
    "\n",
    "axs[1].plot(ai_piezo, label='Piezo Signal', color='blue')\n",
    "axs[1].plot(piezo_timing[:,0], ai_piezo[piezo_timing[:,0]], 'o', label='Piezo Start', color='green')\n",
    "axs[1].plot(piezo_timing[:,1], ai_piezo[piezo_timing[:,1]], 'o', label='Piezo Stop', color='red')\n",
    "\n",
    "\n",
    "\n",
    "axs[2].plot(di_confocal, label='Confocal Camera DI', color='green')\n",
    "# plot confocal start idx\n",
    "axs[2].plot(confocal_start_sample_di, di_confocal[confocal_start_sample_di], 'o', label='Confocal Start (DI)', color='red')\n",
    "# plot confocal rise and fall times\n",
    "axs[2].plot(di_confocal_rise, di_confocal[di_confocal_rise], 'x', label='Confocal Rise (DI)', color='red')\n",
    "axs[2].plot(di_confocal_fall, di_confocal[di_confocal_fall], 'x', label='Confocal Fall (DI)', color='red')\n",
    "\n",
    "axs[3].plot(di_nir, label='NIR Camera DI', color='magenta')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9d1e4d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "the detected trigger count is different from the image id data by more than 3",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m _ = importlib.reload(sys.modules[\u001b[33m'\u001b[39m\u001b[33msync\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msync\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sync_timing_from_h5\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m confocal_to_nir, nir_to_confocal, timing_stack, timing_nir, timing_piezo = \u001b[43msync_timing_from_h5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh5_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# with h5py.File(h5_path, 'r') as f:\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#     daqmx_ai = f['daqmx_ai'][:]\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#     daqmx_di = f['daqmx_di'][:]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m \u001b[38;5;66;03m#                 q_iter_save,\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m#                 n_img_nir)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\munib\\POSTDOC\\CODE\\g5ht-pipeline\\antsun\\sync.py:593\u001b[39m, in \u001b[36msync_timing_from_h5\u001b[39m\u001b[34m(path_h5, n_rec)\u001b[39m\n\u001b[32m    590\u001b[39m di_nir   = daqmx_di[:, \u001b[32m1\u001b[39m].astype(np.float32)\n\u001b[32m    591\u001b[39m di_confocal = daqmx_di[:, \u001b[32m0\u001b[39m].astype(np.float32)\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync_timing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdi_confocal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mai_laser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdi_nir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mai_piezo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_iter_save\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_img_nir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\munib\\POSTDOC\\CODE\\g5ht-pipeline\\antsun\\sync.py:543\u001b[39m, in \u001b[36msync_timing\u001b[39m\u001b[34m(di_confocal, ai_laser, di_nir, ai_piezo, img_id, q_iter_save, n_img_nir)\u001b[39m\n\u001b[32m    541\u001b[39m timing_stack = np.column_stack(detect_confocal_timing_di(di_confocal))\n\u001b[32m    542\u001b[39m \u001b[38;5;66;03m# timing_nir   = detect_nir_timing(di_nir, img_id, q_iter_save, n_img_nir)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m timing_nir   = \u001b[43mdetect_nir_timing_v3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdi_nir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_iter_save\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_img_nir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    544\u001b[39m timing_piezo = detect_piezo_timing(ai_piezo, timing_stack[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m], timing_stack[-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m])\n\u001b[32m    546\u001b[39m confocal_to_nir  = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\munib\\POSTDOC\\CODE\\g5ht-pipeline\\antsun\\sync.py:233\u001b[39m, in \u001b[36mdetect_nir_timing_v3\u001b[39m\u001b[34m(di_nir, img_id, q_iter_save, n_img_nir)\u001b[39m\n\u001b[32m    231\u001b[39m img_id_diff = np.concatenate(([\u001b[32m1\u001b[39m], img_id_diff))\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mlen\u001b[39m(list_nir_on) - np.sum(np.diff(img_id))) > \u001b[32m3\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    234\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthe detected trigger count is different from the image id data by more than 3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    235\u001b[39m     )\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    237\u001b[39m     img_id_diff[-\u001b[32m1\u001b[39m] += \u001b[38;5;28mlen\u001b[39m(list_nir_on) - np.sum(np.diff(img_id)) - \u001b[32m1\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: the detected trigger count is different from the image id data by more than 3"
     ]
    }
   ],
   "source": [
    "# try just running sync_timing\n",
    "import sys\n",
    "import importlib\n",
    "_ = importlib.reload(sys.modules['sync'])\n",
    "\n",
    "from sync import sync_timing_from_h5\n",
    "\n",
    "confocal_to_nir, nir_to_confocal, timing_stack, timing_nir, timing_piezo = sync_timing_from_h5(h5_path)\n",
    "\n",
    "\n",
    "\n",
    "# with h5py.File(h5_path, 'r') as f:\n",
    "#     daqmx_ai = f['daqmx_ai'][:]\n",
    "#     daqmx_di = f['daqmx_di'][:]\n",
    "#     n_img_nir = f['img_nir'].shape[0]\n",
    "#     img_metadata = f['img_metadata']\n",
    "#     img_timestamp = img_metadata['img_timestamp'][:]\n",
    "#     img_id = img_metadata[\"img_id\"][:]\n",
    "#     q_iter_save = img_metadata[\"q_iter_save\"][:]\n",
    "        \n",
    "\n",
    "# confocal_to_nir, nir_to_confocal, timing_stack, timing_nir = sync_timing(di_confocal,\n",
    "#                 ai_laser,\n",
    "#                 di_nir,\n",
    "#                 img_id,\n",
    "#                 q_iter_save,\n",
    "#                 n_img_nir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa3aa114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1063,    1082],\n",
       "       [   1813,    1833],\n",
       "       [   2063,    2083],\n",
       "       ...,\n",
       "       [2027865, 2027885],\n",
       "       [2028115, 2028135],\n",
       "       [2028365, 2028385]], shape=(7974, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timing_nir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf82fd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  13495,   13535],\n",
       "       [  13560,   13600],\n",
       "       [  13625,   13665],\n",
       "       ...,\n",
       "       [2016881, 2016921],\n",
       "       [2016946, 2016986],\n",
       "       [2017011, 2017051]], shape=(30798, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timing_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "767f7816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  13495,   16158],\n",
       "       [  16158,   18826],\n",
       "       [  18826,   21498],\n",
       "       ...,\n",
       "       [2008620, 2011284],\n",
       "       [2011284, 2013958],\n",
       "       [2013958, 2017051]], shape=(751, 2))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timing_piezo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9750ecaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "751"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f15b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(nir_to_confocal, label='DI NIR', color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df239d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig,axs = plt.subplots(4,1,figsize=(12,8))\n",
    "axs[0].plot(confocal_to_piezo_mapping, label='Confocal to Piezo Mapping', marker='o')\n",
    "axs[0].set_xlabel('Confocal Stack Index')\n",
    "axs[0].set_ylabel('Piezo Stack Index')\n",
    "axs[1].plot(nir_to_piezo_mapping, label='NIR to Piezo Mapping', marker='o')\n",
    "axs[1].set_xlabel('NIR Frame Index')\n",
    "axs[1].set_ylabel('Piezo Stack Index')\n",
    "axs[2].plot(nir_to_confocal_mapping, label='NIR to Confocal Mapping', marker='o')\n",
    "axs[2].set_xlabel('NIR Frame Index')\n",
    "axs[2].set_ylabel('Confocal Stack Index')\n",
    "axs[3].plot(confocal_plane, label='Confocal Plane Number', marker='o')\n",
    "axs[3].set_xlabel('Confocal Stack Index')  \n",
    "axs[3].set_ylabel('Plane Number')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8062d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "zoom = (0, daqmx_ai.shape[1])\n",
    "# zoom = (3257743-100000,3257743)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(15,6), sharex=True)\n",
    "axs[0].plot(ai_laser[zoom[0]:zoom[1]], label='Laser Signal', color='orange')\n",
    "# plot laser signal start idx\n",
    "axs[0].plot(confocal_start_sample_di - zoom[0], ai_laser[confocal_start_sample_di], 'o', label='Confocal Start (DI)', color='red')\n",
    "axs[1].plot(ai_piezo[zoom[0]:zoom[1]], label='Piezo Signal', color='blue')\n",
    "# axs[2].plot(ai_stim[zoom[0]:zoom[1]], label='Stimulus Signal', color='magenta')\n",
    "\n",
    "axs[2].plot(di_confocal[zoom[0]:zoom[1]], label='Confocal Camera DI', color='green')\n",
    "# plot confocal start idx\n",
    "axs[2].plot(confocal_start_sample_di - zoom[0], di_confocal[confocal_start_sample_di], 'o', label='Confocal Start (DI)', color='red')\n",
    "# plot confocal rise and fall times\n",
    "axs[2].plot(di_confocal_rise - zoom[0], di_confocal[di_confocal_rise], 'x', label='Confocal Rise (DI)', color='red')\n",
    "axs[2].plot(di_confocal_fall - zoom[0], di_confocal[di_confocal_fall], 'x', label='Confocal Fall (DI)', color='red')\n",
    "\n",
    "axs[3].plot(di_nir[zoom[0]:zoom[1]], label='NIR Camera DI', color='magenta')\n",
    "# # plot nir rise and fall times\n",
    "# axs[3].plot(di_nir_rise - zoom[0], di_nir[di_nir_rise], 'x', label='NIR Rise (DI)', color='black')\n",
    "# axs[3].plot(di_nir_fall - zoom[0], di_nir[di_nir_fall], 'x', label='NIR Fall (DI)', color='black')\n",
    "\n",
    "# # plot piezo peaks\n",
    "# # find number of peaks within zoom range\n",
    "# num_peaks_in_zoom = np.sum((peaks >= zoom[0]) & (peaks <= zoom[1]))\n",
    "# axs[1].plot(peaks[0:num_peaks_in_zoom]-zoom[0], ai_piezo[peaks[0:num_peaks_in_zoom]], 'o', label='Piezo End', color='red')\n",
    "# # plot piezo start from peak\n",
    "# axs[1].plot(np.array(piezo_start_idx_from_peak[0:num_peaks_in_zoom])-zoom[0], ai_piezo[piezo_start_idx_from_peak[0:num_peaks_in_zoom]], 'x', label='Piezo Start', color='red')\n",
    "# for ax in axs:\n",
    "#     ax.legend(loc='upper right', bbox_to_anchor=(1.35, 1), fontsize=12)\n",
    "#     ax.set_ylabel('Signal')\n",
    "# axs[-1].set_xlabel('Sample Index')\n",
    "# # plt.suptitle('Raw DAQ Signals (used for sync)', fontsize=14, fontweight='bold')\n",
    "plt.xlim(0, zoom[1]-zoom[0])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f54587",
   "metadata": {},
   "source": [
    "## MAKE VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adc7f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(h5_path, 'r') as f:\n",
    "    im = f.get('img_nir')[:] # THW\n",
    "sz = im.shape\n",
    "\n",
    "fps = 20.0  # frames per second\n",
    "\n",
    "print('Video shape: ', sz)\n",
    "\n",
    "nframes = im.shape[0]\n",
    "record_duration = nframes / fps # in seconds\n",
    "\n",
    "print('Recording duration (s): ', record_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86443012",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save im, which is of shape (frame, height, width) as a .mp4 video\n",
    "import cv2\n",
    "out_fn = 'nir_video_synced.mp4'\n",
    "if not os.path.exists(PTH):\n",
    "    os.makedirs(PTH)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(out_fn, fourcc, fps, (sz[2], sz[1]), isColor=False)\n",
    "# save video\n",
    "for i in range(nframes):\n",
    "# for i in range(500):\n",
    "    # skip frame if recording has not started based on confocal_timing and nir_timing\n",
    "    nir_start, nir_end = nir_timing[i, 0], nir_timing[i, 1]\n",
    "    if nir_start < confocal_timing[0, 0]:\n",
    "        continue\n",
    "\n",
    "    # find the confocal_timing row for this nir frame\n",
    "    confocal_row = np.where((confocal_timing[:,0] <= nir_start) & (confocal_timing[:,1] >= nir_start))[0]\n",
    "    if len(confocal_row) == 0:\n",
    "        continue\n",
    "    confocal_row = confocal_row[0]\n",
    "    \n",
    "    stack_number = confocal_timing_stack_number[confocal_row]\n",
    "    plane_number = confocal_plane[confocal_row]\n",
    "\n",
    "    \n",
    "\n",
    "    # print status every 100 frames\n",
    "    if i % 100 == 0:\n",
    "        print('Saving frame: ', i, ' / ', nframes)\n",
    "    frame = im[i,:,:]\n",
    "    frame = (frame / np.max(frame) * 255).astype(np.uint8)\n",
    "    # overlay frame with text of frame number and time in seconds\n",
    "    time_sec = i / fps\n",
    "    text = f'Frame: {i}  Time: {time_sec:.2f} sec  Stack: {stack_number if not np.isnan(stack_number) else \"N/A\"}  Plane: {plane_number if not np.isnan(plane_number) else \"N/A\"} '\n",
    "    # text = f'Frame: {i}  Time: {time_sec:.2f} sec  Stack: {confocal_timing_stack_number[i] if i < len(confocal_timing_stack_number) else \"N/A\"}  Plane: {confocal_plane[i] if i < len(confocal_plane) else \"N/A\"} '\n",
    "    cv2.putText(frame, text, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255), 2)\n",
    "    # frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "    out.write(frame)\n",
    "\n",
    "\n",
    "\n",
    "out.release()\n",
    "print('Saved video to: ', out_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9905321d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video shape:  (12780, 732, 968)\n",
      "Recording duration (s):  639.0\n",
      "Saving frame:  0  /  12780\n",
      "Saving frame:  100  /  12780\n",
      "Saving frame:  200  /  12780\n",
      "Saving frame:  300  /  12780\n",
      "Saving frame:  400  /  12780\n",
      "Saving frame:  500  /  12780\n",
      "Saving frame:  600  /  12780\n",
      "Saving frame:  700  /  12780\n",
      "Saving frame:  800  /  12780\n",
      "Saving frame:  900  /  12780\n",
      "Saving frame:  1000  /  12780\n",
      "Saving frame:  1100  /  12780\n",
      "Saving frame:  1200  /  12780\n",
      "Saving frame:  1300  /  12780\n",
      "Saving frame:  1400  /  12780\n",
      "Saving frame:  1500  /  12780\n",
      "Saving frame:  1600  /  12780\n",
      "Saving frame:  1700  /  12780\n",
      "Saving frame:  1800  /  12780\n",
      "Saving frame:  1900  /  12780\n",
      "Saving frame:  2000  /  12780\n",
      "Saving frame:  2100  /  12780\n",
      "Saving frame:  2200  /  12780\n",
      "Saving frame:  2300  /  12780\n",
      "Saving frame:  2400  /  12780\n",
      "Saving frame:  2500  /  12780\n",
      "Saving frame:  2600  /  12780\n",
      "Saving frame:  2700  /  12780\n",
      "Saving frame:  2800  /  12780\n",
      "Saving frame:  2900  /  12780\n",
      "Saving frame:  3000  /  12780\n",
      "Saving frame:  3100  /  12780\n",
      "Saving frame:  3200  /  12780\n",
      "Saving frame:  3300  /  12780\n",
      "Saving frame:  3400  /  12780\n",
      "Saving frame:  3500  /  12780\n",
      "Saving frame:  3600  /  12780\n",
      "Saving frame:  3700  /  12780\n",
      "Saving frame:  3800  /  12780\n",
      "Saving frame:  3900  /  12780\n",
      "Saving frame:  4000  /  12780\n",
      "Saving frame:  4100  /  12780\n",
      "Saving frame:  4200  /  12780\n",
      "Saving frame:  4300  /  12780\n",
      "Saving frame:  4400  /  12780\n",
      "Saving frame:  4500  /  12780\n",
      "Saving frame:  4600  /  12780\n",
      "Saving frame:  4700  /  12780\n",
      "Saving frame:  4800  /  12780\n",
      "Saving frame:  4900  /  12780\n",
      "Saving frame:  5000  /  12780\n",
      "Saving frame:  5100  /  12780\n",
      "Saving frame:  5200  /  12780\n",
      "Saving frame:  5300  /  12780\n",
      "Saving frame:  5400  /  12780\n",
      "Saving frame:  5500  /  12780\n",
      "Saving frame:  5600  /  12780\n",
      "Saving frame:  5700  /  12780\n",
      "Saving frame:  5800  /  12780\n",
      "Saving frame:  5900  /  12780\n",
      "Saving frame:  6000  /  12780\n",
      "Saving frame:  6100  /  12780\n",
      "Saving frame:  6200  /  12780\n",
      "Saving frame:  6300  /  12780\n",
      "Saving frame:  6400  /  12780\n",
      "Saving frame:  6500  /  12780\n",
      "Saving frame:  6600  /  12780\n",
      "Saving frame:  6700  /  12780\n",
      "Saving frame:  6800  /  12780\n",
      "Saving frame:  6900  /  12780\n",
      "Saving frame:  7000  /  12780\n",
      "Saving frame:  7100  /  12780\n",
      "Saving frame:  7200  /  12780\n",
      "Saving frame:  7300  /  12780\n",
      "Saving frame:  7400  /  12780\n",
      "Saving frame:  7500  /  12780\n",
      "Saving frame:  7600  /  12780\n",
      "Saving frame:  7700  /  12780\n",
      "Saving frame:  7800  /  12780\n",
      "Saving frame:  7900  /  12780\n",
      "Saving frame:  8000  /  12780\n",
      "Saving frame:  8100  /  12780\n",
      "Saving frame:  8200  /  12780\n",
      "Saving frame:  8300  /  12780\n",
      "Saving frame:  8400  /  12780\n",
      "Saving frame:  8500  /  12780\n",
      "Saving frame:  8600  /  12780\n",
      "Saving frame:  8700  /  12780\n",
      "Saving frame:  8800  /  12780\n",
      "Saving frame:  8900  /  12780\n",
      "Saving frame:  9000  /  12780\n",
      "Saving frame:  9100  /  12780\n",
      "Saving frame:  9200  /  12780\n",
      "Saving frame:  9300  /  12780\n",
      "Saving frame:  9400  /  12780\n",
      "Saving frame:  9500  /  12780\n",
      "Saving frame:  9600  /  12780\n",
      "Saving frame:  9700  /  12780\n",
      "Saving frame:  9800  /  12780\n",
      "Saving frame:  9900  /  12780\n",
      "Saving frame:  10000  /  12780\n",
      "Saving frame:  10100  /  12780\n",
      "Saving frame:  10200  /  12780\n",
      "Saving frame:  10300  /  12780\n",
      "Saving frame:  10400  /  12780\n",
      "Saving frame:  10500  /  12780\n",
      "Saving frame:  10600  /  12780\n",
      "Saving frame:  10700  /  12780\n",
      "Saving frame:  10800  /  12780\n",
      "Saving frame:  10900  /  12780\n",
      "Saving frame:  11000  /  12780\n",
      "Saving frame:  11100  /  12780\n",
      "Saving frame:  11200  /  12780\n",
      "Saving frame:  11300  /  12780\n",
      "Saving frame:  11400  /  12780\n",
      "Saving frame:  11500  /  12780\n",
      "Saving frame:  11600  /  12780\n",
      "Saving frame:  11700  /  12780\n",
      "Saving frame:  11800  /  12780\n",
      "Saving frame:  11900  /  12780\n",
      "Saving frame:  12000  /  12780\n",
      "Saving frame:  12100  /  12780\n",
      "Saving frame:  12200  /  12780\n",
      "Saving frame:  12300  /  12780\n",
      "Saving frame:  12400  /  12780\n",
      "Saving frame:  12500  /  12780\n",
      "Saving frame:  12600  /  12780\n",
      "Saving frame:  12700  /  12780\n",
      "Saved video to:  nir_video.mp4\n"
     ]
    }
   ],
   "source": [
    "# save raw nir video\n",
    "with h5py.File(h5_path, 'r') as f:\n",
    "    im = f.get('img_nir')[:] # THW\n",
    "sz = im.shape\n",
    "\n",
    "fps = 20.0  # frames per second\n",
    "\n",
    "print('Video shape: ', sz)\n",
    "\n",
    "nframes = im.shape[0]\n",
    "record_duration = nframes / fps # in seconds\n",
    "\n",
    "print('Recording duration (s): ', record_duration)\n",
    "# save im, which is of shape (frame, height, width) as a .mp4 video\n",
    "import cv2\n",
    "out_fn = 'nir_video.mp4'\n",
    "if not os.path.exists(PTH):\n",
    "    os.makedirs(PTH)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(out_fn, fourcc, fps, (sz[2], sz[1]), isColor=False)\n",
    "# save video\n",
    "for i in range(nframes):\n",
    "\n",
    "\n",
    "    # print status every 100 frames\n",
    "    if i % 100 == 0:\n",
    "        print('Saving frame: ', i, ' / ', nframes)\n",
    "    frame = im[i,:,:]\n",
    "    frame = (frame / np.max(frame) * 255).astype(np.uint8)\n",
    "    # overlay frame with text of frame number and time in seconds\n",
    "    time_sec = i / fps\n",
    "    text = f'Frame: {i}  Time: {time_sec:.2f} sec '\n",
    "    # text = f'Frame: {i}  Time: {time_sec:.2f} sec  Stack: {confocal_timing_stack_number[i] if i < len(confocal_timing_stack_number) else \"N/A\"}  Plane: {confocal_plane[i] if i < len(confocal_plane) else \"N/A\"} '\n",
    "    cv2.putText(frame, text, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255), 2)\n",
    "    # frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "    out.write(frame)\n",
    "\n",
    "out.release()\n",
    "print('Saved video to: ', out_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaffe584",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- put all this code together to deliver a synced recording\n",
    "  - will need to figure out what params, data_dicts, and outputs from get_timing_info in the antsun notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db744255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
