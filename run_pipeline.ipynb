{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1b7a0b",
   "metadata": {},
   "source": [
    "# G5HT-PIPELINE\n",
    "\n",
    "## TODO:\n",
    "\n",
    "1. I wonder if I computed a spline on each and every z slice and warped each, oriented each of them, and warped each of them, if the problem of weirdly sheared image stacks would be solved\n",
    "2. quick mp4 for all recordings\n",
    "   1. now working in engaging, works per one nd2 sbatch\n",
    "3. focus check for all recordings\n",
    "   1. maybe focus check can be used to specify which z slices are good to use and which frames are good to use\n",
    "4. for recordings starting in december 2025, need to trim first 2 rather than last 2 z slices\n",
    "5. flip worms so that VNC is always up\n",
    "6. fixed mask could be automated, but if not, make sure to save which index is fixed\n",
    "7. extract behavior\n",
    "8. posture similarity\n",
    "   1. posture might consist of the spline + thresholded z-stack\n",
    "      1. I'm thinking that the orientation shouldn't matter, but the z-planes in focus will, and curvature/spline of the head will\n",
    "      2. maybe need to actually interpolate to 117 z slices\n",
    "   2. sub registration problems\n",
    "   3. label each set of registered frames with one set of ROIs, or auto segment ROIs from each set of registered frames\n",
    "9.  track z over time, which zslices are consistent\n",
    "   1. focus + correlation\n",
    "10. beads -> train/test\n",
    "11. gfp+1 relative to rfp channel (might only apply to pre december 2025 recordings)\n",
    "12. wholistic \n",
    "    1.  parameter sweep, might change\n",
    "    2.  python version\n",
    "    3.  actually, wholistic might be tricky to use all the time, because it only works after parameter optimization, which I don't really know how to automate\n",
    "13. autocorr/scorr\n",
    "14. automate z slice trimming\n",
    "    1.  pre december 2025 (trim last 2 z slices)\n",
    "    2.  post december 2025 (trim first z slice)\n",
    "15. photobleaching estimation?\n",
    "    1.  record immo with serotonin\n",
    "    2.  at least do it for RFP\n",
    "16. try deltaF/F [ (F(t) - F0) / F0 ]\n",
    "18. maybe remove right-most part of the worm where spline is usually kinked\n",
    "19. port everything to engaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2c1c6a",
   "metadata": {},
   "source": [
    "## CONDA ENVIRONMENTS\n",
    "\n",
    "For steps __1. preprocess__ and __2. mip__, `conda activate g5ht-pipeline`\n",
    "\n",
    "For step __3. segment__, `conda activate segment-torch` or `conda activate torchcu129`\n",
    "\n",
    "For step __4. spline, 5. orient, 6. warp, 7. reg__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e087d8",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21220aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    import utils\n",
    "    is_torch_env = False\n",
    "except ImportError:\n",
    "    is_torch_env = True\n",
    "    print(\"utils not loaded because conda environment doesn't have nd2reader installed. probably using torchcu129 env, which is totally fine for just doing the segmentation step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a415d0",
   "metadata": {},
   "source": [
    "## SPECIFY DATA TO PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdcf1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date-20251223_strain-ISg5HT_condition-starvedpatch_worm005.nd2\n",
      "Num z-slices:  41\n",
      "Number of frames:  1200\n",
      "Height:  512\n",
      "width:  512\n",
      "Number of channels:  2\n",
      "Beads alignment file:  D:\\DATA\\g5ht-free\\20251223\\date-20251223_strain-ISg5HT_condition-starvedpatch_worm005_chan_alignment.nd2\n"
     ]
    }
   ],
   "source": [
    "DATA_PTH = r'D:\\DATA'\n",
    "PROJECT = 'g5ht-free' # g5ht-free or g5ht-immo\n",
    "DATE = '20251223'\n",
    "\n",
    "DATA_PTH = os.path.join(DATA_PTH, PROJECT, DATE)\n",
    "\n",
    "INPUT_ND2 = f'date-20251223_strain-ISg5HT_condition-starvedpatch_worm005.nd2'\n",
    "\n",
    "INPUT_ND2_PTH = os.path.join(DATA_PTH, INPUT_ND2)\n",
    "\n",
    "NOISE_PTH = r'C:\\Users\\munib\\POSTDOC\\CODE\\g5ht-pipeline\\noise\\noise_111125.tif'\n",
    "\n",
    "\n",
    "\n",
    "OUT_DIR = os.path.splitext(INPUT_ND2_PTH)[0]\n",
    "\n",
    "STACK_LENGTH = 41 if 'immo' not in INPUT_ND2 else 122\n",
    "\n",
    "if not is_torch_env:\n",
    "    noise_stack = utils.get_noise_stack(NOISE_PTH, STACK_LENGTH)\n",
    "    num_frames, height, width, num_channels = utils.get_range_from_nd2(INPUT_ND2_PTH, stack_length=STACK_LENGTH) \n",
    "    # num_frames = 1200\n",
    "    # height = 512\n",
    "    # width = 512\n",
    "    # num_channels = 2\n",
    "    beads_alignment_file = utils.get_beads_alignment_file(INPUT_ND2_PTH)\n",
    "else:\n",
    "    print(\"utils not loaded because conda environment doesn't have nd2reader installed. probably using torchcu129 env, which is totally fine for just doing the segmentation step\")\n",
    "\n",
    "print(INPUT_ND2)\n",
    "print('Num z-slices: ', STACK_LENGTH)\n",
    "if not is_torch_env:\n",
    "    print('Number of frames: ', num_frames)\n",
    "    print('Height: ', height)\n",
    "    print('width: ', width)\n",
    "    print('Number of channels: ', num_channels)\n",
    "    print('Beads alignment file: ', beads_alignment_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5702d46",
   "metadata": {},
   "source": [
    "## 0. PROCESS BEADS ALIGNMENT DATA (OPTIONAL, CHANGING THIS SO BEADS ARE PROCESSED SEAMLESSLY IN PIPELINE)\n",
    "\n",
    "` conda activate g5ht-pipeline`\n",
    "\n",
    "The registration parameters between green and red channels will be applied to worm recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d8333",
   "metadata": {},
   "source": [
    "### SHEAR CORRECT AND CHANNEL REGISTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a6273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_parallel import main as preprocess_nd2_parallel\n",
    "_ = importlib.reload(sys.modules['preprocess_parallel'])\n",
    "\n",
    "num_frames_beads, _, _, _ = utils.get_range_from_nd2(beads_alignment_file, stack_length=STACK_LENGTH) \n",
    "\n",
    "# # command-line arguments\n",
    "sys.argv = [\"\", beads_alignment_file, \"0\", str(num_frames_beads-1), NOISE_PTH, STACK_LENGTH, 5, num_frames_beads, height, width, num_channels]\n",
    "\n",
    "# # Call the main function\n",
    "preprocess_nd2_parallel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc57a3e8",
   "metadata": {},
   "source": [
    "### MIP\n",
    "\n",
    "This step saved the median channel registration parameters, need to do this somewhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7099cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mip import main as mip\n",
    "\n",
    "_ = importlib.reload(sys.modules['mip'])\n",
    "_ = importlib.reload(sys.modules['utils'])\n",
    "\n",
    "# command-line arguments\n",
    "sys.argv = [\"\", beads_alignment_file, STACK_LENGTH, num_frames_beads, 2]\n",
    "\n",
    "# Call the main function\n",
    "mip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d28b53",
   "metadata": {},
   "source": [
    "## 1. SHEAR CORRECTION\n",
    "\n",
    "` conda activate g5ht-pipeline`\n",
    "\n",
    "- shear corrects each volume\n",
    "  - depending on each exposure time, it can take roughly half a second between the first and last frames of a volume, so any movements need to be corrected for\n",
    "- creates one `.tif` for each volume and stores it in the `shear_corrected` directory\n",
    "\n",
    "##### TODO: should probably update stack length after shear correction since we cut it by 2, although not sure it's explicitly needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed7e3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 11 stacks (100-110) using 12 workers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:18<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable bool object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRemoteTraceback\u001b[39m                           Traceback (most recent call last)",
      "\u001b[31mRemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\munib\\anaconda3\\envs\\g5ht-pipeline\\Lib\\multiprocessing\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ~~~~^^^^^^^^^^^^^^^\n  File \"c:\\Users\\munib\\POSTDOC\\CODE\\g5ht-pipeline\\shear_correct.py\", line 94, in process_one\n    stack = get_stack(input_nd2, index, noise_stack, stack_shape, zplane_to_keep)\n  File \"c:\\Users\\munib\\POSTDOC\\CODE\\g5ht-pipeline\\shear_correct.py\", line 45, in get_stack\n    start, end = zplane_to_keep\n    ^^^^^^^^^^\nTypeError: cannot unpack non-iterable bool object\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m sys.argv = [\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, INPUT_ND2_PTH, start_index, end_index, NOISE_PTH, STACK_LENGTH, cpu_count, num_frames, height, width, num_channels, skip_shear_correction]\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Call the main function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mshear_correct\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\munib\\POSTDOC\\CODE\\g5ht-pipeline\\shear_correct.py:135\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m stacks (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_workers\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m workers...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes=n_workers) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimap_unordered\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_one\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_nd2\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_nd2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_stack\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnoise_stack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstack_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstack_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzplane_to_keep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mz2keep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_shear_correction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_shear_correction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mParallel preprocessing complete.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\munib\\anaconda3\\envs\\g5ht-pipeline\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\munib\\anaconda3\\envs\\g5ht-pipeline\\Lib\\multiprocessing\\pool.py:873\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m    872\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[31mTypeError\u001b[39m: cannot unpack non-iterable bool object"
     ]
    }
   ],
   "source": [
    "import shear_correct\n",
    "_ = importlib.reload(sys.modules['shear_correct'])\n",
    "\n",
    "# start_index = \"0\"\n",
    "# end_index = str(num_frames-1)\n",
    "start_index = \"100\"\n",
    "end_index = \"110\"\n",
    "cpu_count = str(int(os.cpu_count() / 2))\n",
    "# cpu_count = str(int(os.cpu_count()))\n",
    "skip_shear_correction = True # if True, will just denoise and save as tif\n",
    "\n",
    "# sys.argv = [\"\", nd2 file, start_frame, end_frame, noise_pth, stack_length, n_workers, num_frames, height, width, num_channels]\n",
    "sys.argv = [\"\", INPUT_ND2_PTH, start_index, end_index, NOISE_PTH, STACK_LENGTH, cpu_count, num_frames, height, width, num_channels, z2keep, skip_shear_correction]\n",
    "\n",
    "# Call the main function\n",
    "shear_correct.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1357bd32",
   "metadata": {},
   "source": [
    "## 2. CHANNEL ALIGNMENT\n",
    "\n",
    "` conda activate g5ht-pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0617b",
   "metadata": {},
   "source": [
    "### 2a. GET MEDIAN CHANNEL ALIGNMENT PARAMETERS FROM ALL FRAMES\n",
    "\n",
    "- If channel alignment file found, uses that, if not uses worm recording\n",
    "- creates a `.txt` file for each volume that contains elastix channel registration parameters\n",
    "- creates `chan_align_params.csv` and  `chan_align.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e5cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "beads_alignment_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87844a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_channel_alignment\n",
    "import median_channel_alignment\n",
    "_ = importlib.reload(sys.modules['get_channel_alignment'])\n",
    "_ = importlib.reload(sys.modules['median_channel_alignment'])\n",
    "\n",
    "## set beads_alignment_file to None to use worm recording for channel alignment, even if beads file exists\n",
    "# beads_alignment_file = None\n",
    "\n",
    "start_index = \"0\"\n",
    "# cpu_count = str(int(os.cpu_count() / 2))\n",
    "cpu_count = str(int(os.cpu_count()))\n",
    "\n",
    "if beads_alignment_file is not None:\n",
    "    align_with_beads = True\n",
    "    num_frames_beads, _, _, _ = utils.get_range_from_nd2(beads_alignment_file, stack_length=STACK_LENGTH) \n",
    "    sys.argv = [\"\", beads_alignment_file, start_index, str(num_frames_beads-1), NOISE_PTH, STACK_LENGTH, cpu_count, num_frames_beads, height, width, num_channels, align_with_beads]\n",
    "else:\n",
    "    align_with_beads = False\n",
    "    sys.argv = [\"\", INPUT_ND2_PTH, start_index, str(num_frames-1), NOISE_PTH, STACK_LENGTH, cpu_count, num_frames, height, width, num_channels, align_with_beads]\n",
    "\n",
    "# # Call the main function\n",
    "get_channel_alignment.main()\n",
    "median_channel_alignment.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe582c3e",
   "metadata": {},
   "source": [
    "### 2b. APPLY MEDIAN CHANNEL ALIGNMENT PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b97453",
   "metadata": {},
   "source": [
    "- ouputs aligned volumes in `channel_aligned` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apply_channel_alignment\n",
    "_ = importlib.reload(sys.modules['apply_channel_alignment'])\n",
    "\n",
    "start_index = \"0\"\n",
    "# cpu_count = str(int(os.cpu_count() / 2))\n",
    "cpu_count = str(int(os.cpu_count()))\n",
    "\n",
    "# 0786 to 0799 are bad frames in worm005.nd2, copied 0785 for each of those frames\n",
    "\n",
    "if beads_alignment_file is not None:\n",
    "    align_with_beads = True\n",
    "    num_frames_beads, _, _, _ = utils.get_range_from_nd2(beads_alignment_file, stack_length=STACK_LENGTH) \n",
    "    sys.argv = [\"\", INPUT_ND2_PTH, start_index, str(num_frames-1), NOISE_PTH, STACK_LENGTH, cpu_count, num_frames, height, width, num_channels, align_with_beads, beads_alignment_file]\n",
    "else:\n",
    "    align_with_beads = False\n",
    "    sys.argv = [\"\", INPUT_ND2_PTH, start_index, str(num_frames-1), NOISE_PTH, STACK_LENGTH, cpu_count, num_frames, height, width, num_channels, align_with_beads]\n",
    "\n",
    "\n",
    "# Call the main function\n",
    "apply_channel_alignment.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0aece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create copies of 0785 and rename it to 0786 to 0799\n",
    "# import shutil\n",
    "# for i in range(786, 800):\n",
    "#     shutil.copyfile(r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251223\\date-20251223_strain-ISg5HT_condition-starvedpatch_worm005\\channel_aligned\\0785.tif',\n",
    "#                     r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251223\\date-20251223_strain-ISg5HT_condition-starvedpatch_worm005\\channel_aligned\\{:04d}.tif'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdc706e",
   "metadata": {},
   "source": [
    "### 2c. PLOT CHANNEL ALIGNMENT PARAMETER DISTRIBUTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708547d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9193ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# make font sizes larger for visibility\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "try:\n",
    "    out_dir = os.path.splitext(INPUT_ND2_PTH)[0]\n",
    "\n",
    "    df = pd.read_csv(os.path.join(out_dir, 'chan_align_params.csv'))\n",
    "    params = ['TransformParameter_0', 'TransformParameter_1', 'TransformParameter_2', 'TransformParameter_3', 'TransformParameter_4', 'TransformParameter_5']\n",
    "    labels = ['Rx', 'Ry', 'Rz', 'Tx', 'Ty', 'Tz']\n",
    "\n",
    "    # the xaxis limits for each subplot should be the same across figures\n",
    "\n",
    "    xlims = np.zeros((6,2))\n",
    "\n",
    "    plt.figure(figsize=(12,8), tight_layout=True)\n",
    "    for i,param in enumerate(params):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        plt.hist(df[param], bins=30, color='red', alpha=0.6)\n",
    "        # plot the median value as a vertical line\n",
    "        median_value = df[param].median()\n",
    "        plt.axvline(median_value, color='black', linestyle='dashed', linewidth=2)\n",
    "        plt.xlabel(labels[i])\n",
    "        plt.ylabel('Frequency')\n",
    "        # get xaxis limits\n",
    "        xlims[i,:] = plt.xlim()\n",
    "        # title is median value\n",
    "        plt.title(f'Median: {np.round(median_value,3)}', fontsize=14)\n",
    "    plt.show()\n",
    "except FileNotFoundError:\n",
    "    print(\"No chan_align_params.csv found for worm recording\")\n",
    "\n",
    "out_dir = os.path.splitext(INPUT_ND2_PTH)[0] + '_chan_alignment'\n",
    "df = pd.read_csv(os.path.join(out_dir, 'chan_align_params.csv'))\n",
    "params = ['TransformParameter_0', 'TransformParameter_1', 'TransformParameter_2', 'TransformParameter_3', 'TransformParameter_4', 'TransformParameter_5']\n",
    "labels = ['Rx', 'Ry', 'Rz', 'Tx', 'Ty', 'Tz']\n",
    "\n",
    "plt.figure(figsize=(12,8), tight_layout=True)\n",
    "for i,param in enumerate(params):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.hist(df[param], bins=30, color='blue', alpha=0.6)\n",
    "    # plot the median value as a vertical line\n",
    "    median_value = df[param].median()\n",
    "    plt.axvline(median_value, color='black', linestyle='dashed', linewidth=2)\n",
    "    plt.xlabel(labels[i])\n",
    "    plt.ylabel('Frequency')\n",
    "    # apply xlims\n",
    "    # plt.xlim(xlims[i,0], xlims[i,1])\n",
    "    # title is median value, font size 14\n",
    "    plt.title(f'Median: {np.round(median_value,3)}', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599f4640",
   "metadata": {},
   "source": [
    "## 3. BLEACH CORRECTION\n",
    "\n",
    "TODO:\n",
    "- per z slice?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b283de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import bleach_correct\n",
    "_ = importlib.reload(sys.modules['bleach_correct'])\n",
    "\n",
    "\n",
    "PTH = os.path.splitext(INPUT_ND2_PTH)[0]\n",
    "REG_DIR = 'channel_aligned' # 'channel_aligned' or 'tif' \n",
    "channels = 1\n",
    "method = 'block' # 'block' or 'exponential'\n",
    "mode = 'total' # 'total' or 'median'\n",
    "\n",
    "bleach_correct.correct_bleaching(os.path.join(PTH,REG_DIR), channels=channels, method=method, fbc=0.04, intensity_mode=mode)\n",
    "\n",
    "\n",
    "# # Correct RFP only with block method (default)\n",
    "# correct_bleaching(\"path/to/data\")\n",
    "\n",
    "# # Correct both channels with exponential fit\n",
    "# correct_bleaching(\"path/to/data\", channels=[0, 1], method='exponential')\n",
    "\n",
    "# # Command line\n",
    "# python bleach_correct.py path/to/data --channels 0 1 --method exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a097705",
   "metadata": {},
   "source": [
    "## 4. MIP\n",
    "\n",
    "` conda activate g5ht-pipeline`\n",
    "\n",
    "- outputs `means.png`, `focus.png`, `mip.tif`, and `mip.mp4`, `focus_check.csv`\n",
    "\n",
    "##### TODO: \n",
    "- legend for focus.png, should be frame#\n",
    "- mip for xy, xz, zy\n",
    "- mip for several slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8e39b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mip\n",
    "\n",
    "_ = importlib.reload(sys.modules['mip'])\n",
    "_ = importlib.reload(sys.modules['utils'])\n",
    "\n",
    "# command-line arguments\n",
    "framerate = 8\n",
    "# tif_dir = 'bleach_corrected_RFP_block' # one of 'shear_corrected' 'channel_aligned' 'bleach_corrected_RFP_block'\n",
    "tif_dir = 'shear_corrected'\n",
    "rmax = 850\n",
    "gmax = 150\n",
    "mp4_quality = 10\n",
    "do_focus = True\n",
    "sys.argv = [\"\", INPUT_ND2_PTH, tif_dir, STACK_LENGTH, num_frames, framerate, rmax, gmax, mp4_quality, do_focus]\n",
    "\n",
    "# Call the main function\n",
    "mip.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563861dd",
   "metadata": {},
   "source": [
    "## 5 DRIFT ESTIMATION\n",
    "\n",
    "` conda activate g5ht-pipeline`\n",
    "\n",
    "- outputs  `z_selection.csv`, `z_selection_diagnostics.png`, `sharpness.csv`\n",
    "\n",
    "TODO:\n",
    "- use z selection going forward\n",
    "- also use sharpness/focus (and other things) to determine good/bad frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import drift_estimation\n",
    "\n",
    "_ = importlib.reload(sys.modules['drift_estimation'])\n",
    "_ = importlib.reload(sys.modules['utils'])\n",
    "\n",
    "# command-line arguments\n",
    "tif_dir = 'bleach_corrected_RFP_block' # one of 'shear_corrected' 'channel_aligned' 'bleach_corrected_RFP_block'\n",
    "\n",
    "sys.argv = [\"\", INPUT_ND2_PTH, tif_dir, STACK_LENGTH, num_frames]\n",
    "\n",
    "# Call the main function\n",
    "drift_estimation.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6588494",
   "metadata": {},
   "source": [
    "## 5. SEGMENT\n",
    "\n",
    "- outputs `label.tif`, contains segmented MIP for each volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f60d1",
   "metadata": {},
   "source": [
    "__on home pc__: \n",
    "`conda activate segment-torch`\n",
    "\n",
    "Uses a separate conda environment from the rest of the pipeline. create it using:\n",
    "`conda env create -f segment_torch.yml`\n",
    "\n",
    "__on lab pc__: \n",
    "`conda activate torchcu129`\n",
    "\n",
    "Uses a separate conda environment from the rest of the pipeline. create it following steps in:\n",
    "`segment_torch_cu129_environment.yml`\n",
    "\n",
    "### setup each time model weights change\n",
    "Need to set path to model weights as `CHECKPOINT` in `eval_torch.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92795d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segment.segment_torch\n",
    "_ = importlib.reload(sys.modules['segment.segment_torch'])\n",
    "\n",
    "# mip_tif = 'mip_bleach_corrected_RFP_block'\n",
    "mip_tif = 'mip_channel_aligned' \n",
    "\n",
    "MIP_PTH = os.path.join(os.path.splitext(INPUT_ND2_PTH)[0], f'{mip_tif}.tif')\n",
    "\n",
    "# command-line arguments\n",
    "sys.argv = [\"\", MIP_PTH]\n",
    "\n",
    "segment.segment_torch.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4989c725",
   "metadata": {},
   "source": [
    "## 6. SPLINE\n",
    "\n",
    "`conda activate g5ht-pipeline`\n",
    "\n",
    "- outputs `spline.json`, `spline.tif`, and `dilated.tif`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac034f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spline\n",
    "_ = importlib.reload(sys.modules['spline'])\n",
    "\n",
    "LABEL_PTH = MIP_PTH = os.path.join(os.path.splitext(INPUT_ND2_PTH)[0], 'label.tif')\n",
    "\n",
    "# command-line arguments\n",
    "sys.argv = [\"\", LABEL_PTH]\n",
    "\n",
    "spline.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fb7360",
   "metadata": {},
   "source": [
    "## 7. ORIENT\n",
    "\n",
    "`conda activate g5ht-pipeline`\n",
    "\n",
    "- outputs `oriented.json`, `oriented.png`, `oriented_stack.tif`\n",
    "\n",
    "NOTE: `orient_v2.py` automated the process of finding orientation completely, whereas `orient.py` requires you to input the (x,y) nose location on the first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb8bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orient\n",
    "_ = importlib.reload(sys.modules['orient'])\n",
    "\n",
    "SPLINE_PTH = MIP_PTH = os.path.join(os.path.splitext(INPUT_ND2_PTH)[0], 'spline.json')\n",
    "nose_y = 250\n",
    "nose_x = 45\n",
    "\n",
    "# apply constraints\n",
    "# might need this when there are frames where the spline fitting fails and orientation is lost intermittently\n",
    "constrain_frame = 515\n",
    "constrain_frame_nose_y = 288\n",
    "constrain_frame_nose_x = 180\n",
    "\n",
    "# command-line arguments\n",
    "# sys.argv = [\"\", SPLINE_PTH, str(nose_y), str(nose_x)]\n",
    "sys.argv = [\"\", SPLINE_PTH, str(nose_y), str(nose_x), str(constrain_frame), str(constrain_frame_nose_y), str(constrain_frame_nose_x)]\n",
    "\n",
    "orient.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orient_v2 # tried to automate finding nose point, not working well at the moment\n",
    "_ = importlib.reload(sys.modules['orient_v2'])\n",
    "\n",
    "SPLINE_PTH = MIP_PTH = os.path.join(os.path.splitext(INPUT_ND2_PTH)[0], 'spline.json')\n",
    "\n",
    "# command-line arguments\n",
    "sys.argv = [\"\", SPLINE_PTH]\n",
    "\n",
    "orient_v2.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae94ec6",
   "metadata": {},
   "source": [
    "## 8. WARP\n",
    "\n",
    "`conda activate g5ht-pipeline`\n",
    "\n",
    "- ouputs: `warped/*.tif` and `masks/*.tif`\n",
    "\n",
    "TODO: parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1eac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warp\n",
    "_ = importlib.reload(sys.modules['warp'])\n",
    "\n",
    "PTH = os.path.splitext(INPUT_ND2_PTH)[0]\n",
    "\n",
    "start_index = 516\n",
    "end_index = num_frames\n",
    "\n",
    "for i in tqdm(range(start_index, end_index)):\n",
    "    # command-line arguments\n",
    "    sys.argv = [\"\", PTH, i]\n",
    "\n",
    "    warp.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2ddcbc",
   "metadata": {},
   "source": [
    "## 9. REGISTER\n",
    "\n",
    "`conda activate g5ht-pipeline`\n",
    "\n",
    "__ALTERNATIVELY__: register using the wholistic registration algorithm, currently in MATLAB\n",
    "\n",
    "TODO: parallelize / make faster\n",
    "\n",
    "- pick a good representative fixed frame that you want to register everything to\n",
    "  - copy it to the main output folder and name it `fixed_xxxx.tif`\n",
    "  - copy the corresponding mask and name it `fixed_mask_xxxx.tif`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b722e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reg\n",
    "_ = importlib.reload(sys.modules['reg'])\n",
    "\n",
    "PTH = os.path.splitext(INPUT_ND2_PTH)[0]\n",
    "\n",
    "start_index = 222\n",
    "end_index = num_frames\n",
    "zoom = 1 # albert was using 3\n",
    "# zoom = 3\n",
    "\n",
    "for i in tqdm(range(start_index, end_index)):\n",
    "    # command-line arguments\n",
    "    try:\n",
    "        sys.argv = [\"\", PTH, i, str(zoom)]\n",
    "        reg.main()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing index {i}: {e}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd56099",
   "metadata": {},
   "source": [
    "### REGISTER WITH GFP+1 TO RFP\n",
    "\n",
    "TRIM LAST RFP ZSLICE, TRIM FIRST GFP ZSLICE\n",
    "\n",
    "seems to be that as of 20251204, all recordings were taken such that the i zslice in red channel corresponds to i+1 zslice in green channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d1eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "\n",
    "from reg_gfp_indexing import main as reg_worm\n",
    "\n",
    "PTH = r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251028\\date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm001_aligned'\n",
    "\n",
    "for i in tqdm(range(1200)):\n",
    "    # command-line arguments\n",
    "    sys.argv = [\"\", PTH, i, \"1\"]\n",
    "    reg_worm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8183d57b",
   "metadata": {},
   "source": [
    "### MAKE MOVIES OF REGISTERED DATA (see `reg_microfilm.ipynb`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f91372",
   "metadata": {},
   "source": [
    "### REGISTER SINGLE FRAMES WITH ERROR LOGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29f1bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "import itk\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from itk import image_view_from_array\n",
    "\n",
    "#get channels out of stacks\n",
    "def register_one(fixed_stack, fixed_mask_stack, moving_stack, moving_mask_stack):\n",
    "\tfixed_rfp = fixed_stack[:, 1].copy()\n",
    "\tmoving_gfp, moving_rfp = moving_stack[:, 0].copy(), moving_stack[:, 1].copy()\n",
    "\n",
    "\t#initialize registration parameters\n",
    "\tparameter_object = itk.ParameterObject.New()\n",
    "\tdefault_rigid_parameter_map = parameter_object.GetDefaultParameterMap('rigid', 4)\n",
    "\tparameter_object.AddParameterMap(default_rigid_parameter_map)\n",
    "\tdefault_affine_parameter_map = parameter_object.GetDefaultParameterMap('affine', 4)\n",
    "\tparameter_object.AddParameterMap(default_affine_parameter_map)\n",
    "\tdefault_bspline_128_parameter_map = parameter_object.GetDefaultParameterMap('bspline', 4, 128)\n",
    "\tparameter_object.AddParameterMap(default_bspline_128_parameter_map)\n",
    "\tdefault_bspline_64_parameter_map = parameter_object.GetDefaultParameterMap('bspline', 4, 64)\n",
    "\tparameter_object.AddParameterMap(default_bspline_64_parameter_map)\n",
    "\tdefault_bspline_32_parameter_map = parameter_object.GetDefaultParameterMap('bspline', 4, 32)\n",
    "\tparameter_object.AddParameterMap(default_bspline_32_parameter_map)\n",
    "\n",
    "\t#convert to itk images\n",
    "\tfixed_rfp = itk.image_view_from_array(fixed_rfp.astype(np.float32))\n",
    "\tmoving_rfp = itk.image_view_from_array(moving_rfp.astype(np.float32))\n",
    "\n",
    "\tfixed_mask_stack = itk.image_view_from_array(fixed_mask_stack.astype(np.ubyte))\n",
    "\tmoving_mask_stack = itk.image_view_from_array(moving_mask_stack.astype(np.ubyte))\n",
    "\n",
    "\t#register rfp first and then apply transform to gfp\n",
    "\n",
    "\tregistered_rfp, transform_parameters = itk.elastix_registration_method(fixed_rfp, moving_rfp, parameter_object,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   fixed_mask=fixed_mask_stack, moving_mask=moving_mask_stack,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   log_to_console=True)\n",
    "\tregistered_gfp = itk.transformix_filter(moving_gfp, transform_parameters)\n",
    "\n",
    "\t#initialize and fill output\n",
    "\toutput_stack = np.zeros((fixed_stack.shape[0], 2, 200, 500), np.uint16)\n",
    "\toutput_stack[:, 0] = np.clip(registered_gfp, 0, 4095)\n",
    "\toutput_stack[:, 1] = np.clip(registered_rfp, 0, 4095)\n",
    "\n",
    "\treturn output_stack\n",
    "    \n",
    "\t# # enablle elastic error logging\n",
    "\t# elastix_filter = itk.ElastixRegistrationMethod.New(fixed_rfp, moving_rfp, parameter_object,\n",
    "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   fixed_mask=fixed_mask_stack, moving_mask=moving_mask_stack,\n",
    "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   log_to_console=True) \n",
    "    \n",
    "\t# elastix_filter.SetParameterObject(parameter_object)\n",
    "\t# elastix_filter.SetNumberOfThreads(8)\n",
    "\t# elastix_filter.LogToConsoleOn()  # Enable console logging\n",
    "\t# elastix_filter.LogToFileOn()\n",
    "\t# elastix_filter.SetOutputDirectory(r\"C:\\Users\\munib\\POSTDOC\\CODE\\g5ht-pipeline\\logs\")\n",
    "\t# elastix_filter.Update()\n",
    "\n",
    "\t# return elastix_filter.GetOutput(), elastix_filter.GetTransformParameterObject()\n",
    "\n",
    "input_dir = os.path.splitext(INPUT_ND2_PTH)[0]\n",
    "warped_path = os.path.join(input_dir, 'warped')\n",
    "output_path = os.path.join(input_dir, 'registered_fixed_sweep')\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "fixed_list = np.arange(0, 400, 50)\n",
    "mov_list = np.arange(0, 400, 30)\n",
    "\n",
    "for fixed in fixed_list:\n",
    "    for mov in mov_list:\n",
    "        print(f'Processing fixed: {fixed}, moving: {mov}')\n",
    "        \n",
    "\t\t# load stacks\n",
    "\t\n",
    "        moving_path = os.path.join(warped_path,f'{mov:04d}.tif')\n",
    "        moving_stack = tifffile.imread(moving_path).astype(np.float32)\n",
    "        fixed_path = os.path.join(warped_path,f'{fixed:04d}.tif')\n",
    "        fixed_stack = tifffile.imread(fixed_path).astype(np.float32)\n",
    "        fixed_mask_path = os.path.join(input_dir, 'masks', f'{fixed:04d}.tif')\n",
    "        fixed_mask = tifffile.imread(fixed_mask_path)\n",
    "        fixed_mask_stack = np.stack([fixed_mask] * fixed_stack.shape[0])\n",
    "\n",
    "        moving_mask_path = os.path.join(input_dir, 'masks', f'{mov:04d}.tif')\n",
    "        moving_mask = tifffile.imread(moving_mask_path)\n",
    "        moving_mask_stack = np.stack([moving_mask] * fixed_stack.shape[0])\n",
    "\n",
    "\n",
    "        output_stack = register_one(fixed_stack, fixed_mask_stack, moving_stack, moving_mask_stack)\n",
    "        # save output stack with fixed and moving indices in filename\n",
    "        output_file_path = os.path.join(output_path, f'fixed_{fixed:04d}_mov_{mov:04d}.tif')\n",
    "        tifffile.imwrite(output_file_path, output_stack, imagej=True)\n",
    "\n",
    "# fixed = 100\n",
    "# mov = 200\n",
    "\n",
    "# # load stacks\n",
    "# moving_path = os.path.join(warped_path,f'{mov:04d}.tif')\n",
    "# moving_stack = tifffile.imread(moving_path).astype(np.float32)\n",
    "# fixed_path = os.path.join(warped_path,f'{fixed:04d}.tif')\n",
    "# fixed_stack = tifffile.imread(fixed_path).astype(np.float32)\n",
    "# fixed_mask_path = os.path.join(input_dir, 'masks', f'{fixed:04d}.tif')\n",
    "# fixed_mask = tifffile.imread(fixed_mask_path)\n",
    "# fixed_mask_stack = np.stack([fixed_mask] * fixed_stack.shape[0])\n",
    "\n",
    "# moving_mask_path = os.path.join(input_dir, 'masks', f'{mov:04d}.tif')\n",
    "# moving_mask = tifffile.imread(moving_mask_path)\n",
    "# moving_mask_stack = np.stack([moving_mask] * fixed_stack.shape[0])\n",
    "\n",
    "\n",
    "# output_stack = register_one(fixed_stack, fixed_mask_stack, moving_stack, moving_mask_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361dec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_stack = register_one(fixed_stack, fixed_mask_stack, moving_stack, moving_mask_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d3ac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bc5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(fixed_stack[10,1,:,:])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(output_stack[10,1,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b034439",
   "metadata": {},
   "source": [
    "## 10. EXTRACT BEHAVIOR\n",
    "\n",
    "`conda activate imgpro` and probably conda/julia\n",
    "\n",
    "- extract NIR video\n",
    "- video viewer to label events (food encounter)\n",
    "- extract behavior with antsun code\n",
    "  - speed can be done now with stage position\n",
    "- sync confocal and nir cams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00383f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hdf5plugin\n",
    "import h5py\n",
    "\n",
    "\n",
    "PTH = r'D:\\DATA\\g5ht-free\\20251223'\n",
    "FN = 'date-20251223_strain-ISg5HT_condition-starvedpatch_worm005'\n",
    "\n",
    "f = h5py.File(os.path.join(PTH,FN + '.h5'), 'r')\n",
    "\n",
    "im = f.get('img_nir')[:] # THW\n",
    "sz = im.shape\n",
    "\n",
    "fps = 20.0  # frames per second\n",
    "\n",
    "print('Video shape: ', sz)\n",
    "\n",
    "nframes = im.shape[0]\n",
    "record_duration = nframes / fps # in seconds\n",
    "\n",
    "print('Recording duration (s): ', record_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708a792a",
   "metadata": {},
   "source": [
    "### SAVE NIR MOVIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc91fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save im, which is of shape (frame, height, width) as a .mp4 video\n",
    "import cv2\n",
    "out_fn = os.path.join(os.path.join(PTH,FN), 'nir_video.mp4')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(out_fn, fourcc, fps, (sz[2], sz[1]), isColor=False)\n",
    "# save video\n",
    "for i in range(nframes):\n",
    "    # print status every 100 frames\n",
    "    if i % 100 == 0:\n",
    "        print('Saving frame: ', i, ' / ', nframes)\n",
    "    frame = im[i,:,:]\n",
    "    frame = (frame / np.max(frame) * 255).astype(np.uint8)\n",
    "    # overlay frame with text of frame number and time in seconds\n",
    "    time_sec = i / fps\n",
    "    text = f'Frame: {i}  Time: {time_sec:.2f} s'\n",
    "    cv2.putText(frame, text, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255), 2)\n",
    "    # frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "    out.write(frame)\n",
    "out.release()\n",
    "print('Saved video to: ', out_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb709f",
   "metadata": {},
   "source": [
    "### SYNC CONFOCAL & NIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hdf5plugin\n",
    "import h5py\n",
    "\n",
    "\n",
    "PTH = r'D:\\DATA\\g5ht-free\\20251223'\n",
    "FN = 'date-20251223_strain-ISg5HT_condition-starvedpatch_worm005'\n",
    "\n",
    "f = h5py.File(os.path.join(PTH,FN + '.h5'), 'r')\n",
    "\n",
    "im = f.get('img_nir')[:] # THW\n",
    "sz = im.shape\n",
    "\n",
    "fps = 20.0  # frames per second\n",
    "\n",
    "print('Video shape: ', sz)\n",
    "\n",
    "nframes = im.shape[0]\n",
    "record_duration = nframes / fps # in seconds\n",
    "\n",
    "print('Recording duration (s): ', record_duration)\n",
    "\n",
    "data_dict = dict()\n",
    "data_dict['input_h5'] = os.path.join(PTH,FN + '.h5')\n",
    "data_dict['n_stack'] = 41\n",
    "input_h5 = data_dict['input_h5']\n",
    "n_stack = data_dict['n_stack']\n",
    "new_dict = {}\n",
    "\n",
    "print('keys:', list(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6196f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('keys:', list(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7250ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f['daqmx_ai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(f['pos_st'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a1d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR CONFOCAL (SIMPLE): confocal is on when daqmx_ai is high and pick when each stack starts\n",
    "confocal_ons = (f['daqmx_di'][0] > 0.5).astype(int)\n",
    "confocal_starts = np.where((np.diff(confocal_ons) == 1))[0]\n",
    "confocal_stack_starts = confocal_starts[range(0, len(confocal_starts), n_stack)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "f['daqmx_di']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a506dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(f['daqmx_ai'][0][0:10000])\n",
    "plt.plot(f['daqmx_ai'][1][0:10000])\n",
    "plt.plot(f['daqmx_ai'][2][0:10000])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(f['daqmx_di'][0][0:10000])\n",
    "plt.plot(f['daqmx_di'][1][0:10000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc53c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "plt.figure()\n",
    "plt.plot(confocal_ons)\n",
    "# overlay confocal_starts as red dots\n",
    "plt.plot(confocal_starts, confocal_ons[confocal_starts], 'ro')\n",
    "# overlay confocal_stack_starts as green dots\n",
    "plt.plot(confocal_stack_starts, confocal_ons[confocal_stack_starts], 'go')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b660fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "confocal_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b18d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR NIR (COMPLICATED): nir is on when daqmx_di is high\n",
    "nir_ons = (f['daqmx_di'][1] > 0.5).astype(int)\n",
    "nir_starts = np.where((np.diff(nir_ons) == 1))[0]\n",
    "\n",
    "#FOR NIR (COMPLICATED): i believe the camera only captures at certain nir ids\n",
    "ids = np.array(f['img_metadata']['img_id'])\n",
    "ids -= ids[0]\n",
    "\n",
    "#FOR NIR (COMPLICATED): i believe the camera only adddionally saves every other frame\n",
    "q = np.array(f['img_metadata']['q_iter_save']) > 0.5\n",
    "filtered_nir_starts = nir_starts[ids[q]]\n",
    "\n",
    "#combine the mappings\n",
    "nir_to_conf_mapping = []\n",
    "for i in confocal_stack_starts:\n",
    "    index = np.argmax(filtered_nir_starts > i)\n",
    "    if index > 0:\n",
    "        nir_to_conf_mapping.append(index)\n",
    "    else:\n",
    "        break\n",
    "new_dict['nir_to_conf_mapping'] = np.array(nir_to_conf_mapping)\n",
    "data_dict.update(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf81687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b3d0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e1f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21914fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8772a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "import nir.sync_nir_confocal_converted\n",
    "_ = importlib.reload(sys.modules['nir.sync_nir_confocal_converted'])\n",
    "\n",
    "\n",
    "# 1. Load and synchronize timing\n",
    "PTH = r'D:\\DATA\\g5ht-free\\20251223'\n",
    "FN = 'date-20251223_strain-ISg5HT_condition-starvedpatch_worm005'\n",
    "path_h5 = os.path.join(PTH, FN + '.h5')\n",
    "confocal_to_nir, nir_to_confocal, timing_stack, timing_nir = nir.sync_nir_confocal_converted.sync_timing_from_file(\n",
    "    path_h5, n_rec=1\n",
    ")\n",
    "\n",
    "print(f\"Confocal frames: {len(confocal_to_nir)}\")\n",
    "print(f\"NIR frames: {len(nir_to_confocal)}\")\n",
    "\n",
    "# 2. Setup complete timing information\n",
    "data_dict = {}\n",
    "param = {\n",
    "    'n_rec': 1,\n",
    "    'max_t': len(confocal_to_nir),\n",
    "    't_range': range(len(confocal_to_nir)),\n",
    "    'FLIR_FPS': 20.0\n",
    "}\n",
    "\n",
    "nir.sync_nir_confocal_converted.get_timing_info(data_dict, param, path_h5, h5_confocal_time_lag=0)\n",
    "\n",
    "# 3. Align behavioral data\n",
    "# Assume you have NIR-rate behavioral data\n",
    "nir_velocity = np.random.randn(len(nir_to_confocal))  # example data\n",
    "confocal_velocity = nir.sync_nir_confocal_converted.nir_vec_to_confocal(\n",
    "    nir_velocity, \n",
    "    data_dict['confocal_to_nir'], \n",
    "    param['max_t']\n",
    ")\n",
    "\n",
    "# 4. Access synchronized timestamps\n",
    "confocal_timestamps = data_dict['timestamps']\n",
    "nir_timestamps = data_dict['nir_timestamps']\n",
    "\n",
    "# 5. Find stimulus onsets\n",
    "stim_frames_confocal = data_dict['stim_begin_confocal']\n",
    "stim_frames_nir = data_dict['stim_begin_nir']\n",
    "\n",
    "print(f\"Stimulus delivered at confocal frames: {stim_frames_confocal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ebfad0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"daqmx_di\": shape (2, 3279948), type \"<u4\">"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['daqmx_di']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "828b0ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1200/1200 [00:00<00:00, 2828.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm001 saved\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import tifffile as tif\n",
    "import tqdm\n",
    "import sys\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "PTH = r'D:\\DATA\\g5ht-free\\20251028'\n",
    "FN = 'date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm001'\n",
    "h5_path = osp.join(PTH, FN + '.h5')\n",
    "n_stack = 41\n",
    "\n",
    "#FOR CONFOCAL (SIMPLE): confocal is on when daqmx_ai is high and pick when each stack starts\n",
    "f = h5py.File(h5_path, 'r')\n",
    "confocal_piezo_ends, _ = signal.find_peaks(f['daqmx_ai'][1], distance=100, prominence=1)\n",
    "\n",
    "#FOR NIR (COMPLICATED): nir is on when daqmx_di is high\n",
    "nir_ons = (f['daqmx_di'][1] > 0.5).astype(int)\n",
    "nir_starts = np.where((np.diff(nir_ons) == 1))[0]\n",
    "\n",
    "#FOR NIR (COMPLICATED): i believe the camera only captures at certain nir ids\n",
    "ids = np.array(f['img_metadata']['img_id'])\n",
    "ids -= ids[0]\n",
    "\n",
    "#FOR NIR (COMPLICATED): i believe the camera only adddionally saves every other frame\n",
    "q = np.array(f['img_metadata']['q_iter_save']) > 0.5\n",
    "filtered_nir_starts = nir_starts[ids[q]]\n",
    "\n",
    "#combine the mappings\n",
    "mapping = np.searchsorted(filtered_nir_starts, confocal_piezo_ends, side='right') - 1\n",
    "\n",
    "#gets the filename\n",
    "name = osp.basename(h5_path).split('.')[0]\n",
    "\n",
    "#saves the nir\n",
    "nir = np.zeros((len(mapping), 732, 968), dtype=np.ubyte)\n",
    "for i, j in tqdm.tqdm(enumerate(mapping), total=len(mapping)):\n",
    "    try:\n",
    "        nir[i] = f['img_nir'][j]\n",
    "    except Exception as e:\n",
    "        break\n",
    "tif.imwrite(f'{name}.tif', nir, imagej=True)\n",
    "\n",
    "#saves the stage position\n",
    "stage_data = np.array(f['pos_stage'])\n",
    "df = pd.DataFrame(stage_data)\n",
    "data = df.interpolate(method='cubic').to_numpy()[mapping]\n",
    "y, x = data.T\n",
    "pd.DataFrame(data).to_csv(f'{name}.csv')\n",
    "print(f'{name} saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bfb71ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm001'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df6e3d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     6,     8, ..., 26039, 26041, 26043], shape=(12826,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0402b4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    899,    1024,    1149, ..., 3253983, 3254108, 3257756],\n",
       "      shape=(26027,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nir_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd95b09f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38bab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b620fdc5",
   "metadata": {},
   "source": [
    "## STARTING OVER ON SYNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33a63d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import tifffile as tif\n",
    "import tqdm\n",
    "import sys\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# PTH = r'D:\\DATA\\g5ht-free\\20251028'\n",
    "# FN = 'date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm001'\n",
    "PTH = r'D:\\DATA\\g5ht-free\\20260123'\n",
    "FN = 'date-20260123_strain-ISg5HT-nsIS180_condition-fedpatch_worm004'\n",
    "\n",
    "h5_path = osp.join(PTH, FN + '.h5')\n",
    "n_stack = 41\n",
    "n_volume = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aad75d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(h5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee4c273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_laser = f['daqmx_ai'][0]\n",
    "ai_piezo = f['daqmx_ai'][1]\n",
    "ai_stim = f['daqmx_ai'][2]\n",
    "di_confocal = f['daqmx_di'][0]\n",
    "di_nir = f['daqmx_di'][1]\n",
    "\n",
    "img_timestamp = f['img_metadata'][\"img_timestamp\"][:]\n",
    "img_id = f['img_metadata'][\"img_id\"][:]\n",
    "q_iter_save = f['img_metadata'][\"q_iter_save\"][:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80b15af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ai_laser(ai_laser: np.ndarray, di_camera: np.ndarray, n_rec: int = 1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Filter laser signal to include only z-stack recording periods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ai_laser : np.ndarray\n",
    "        Laser analog input\n",
    "    di_camera : np.ndarray\n",
    "        Camera digital input\n",
    "    n_rec : int, optional\n",
    "        Number of recordings to keep (default: 1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Filtered laser signal\n",
    "    \"\"\"\n",
    "    n = min(len(ai_laser), len(di_camera))\n",
    "    ai_laser_zstack_only = ai_laser[:n].astype(np.float32)\n",
    "    ai_laser_filter_bit = np.zeros(n, dtype=np.float32)\n",
    "    trg_state = np.zeros(n, dtype=np.float64)\n",
    "\n",
    "    # # validation plots\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # plt.plot(ai_laser_zstack_only, label='Original AI Laser')\n",
    "    # plt.plot(di_camera[:n], label='DI Camera', alpha=0.5)\n",
    "    # plt.title('AI Laser and DI Camera Signals')\n",
    "    # plt.xlabel('Sample Index')\n",
    "    # plt.ylabel('Signal Amplitude')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    n_kernel = 100\n",
    "    for i in range(n):\n",
    "        start = max(0, i - n_kernel)\n",
    "        stop = min(n, i + n_kernel + 1)\n",
    "        trg_state[i] = np.max(di_camera[start:stop])\n",
    "\n",
    "    delta_trg_state = np.diff(trg_state)\n",
    "    list_idx_start = np.where(delta_trg_state == 1)[0]\n",
    "    list_idx_end = np.where(delta_trg_state == -1)[0]\n",
    "\n",
    "    if n_rec > len(list_idx_start):\n",
    "        raise ValueError(\"filter_ai_laser: not enough recordings detected. check n_rec\")\n",
    "\n",
    "    # Get n_rec longest recordings\n",
    "    rec_lengths = list_idx_end - list_idx_start\n",
    "    list_idx_rec = np.argsort(rec_lengths)[::-1][:n_rec]\n",
    "    \n",
    "    for i in list_idx_rec:\n",
    "        ai_laser_filter_bit[list_idx_start[i]+1:list_idx_end[i]] = 1\n",
    "\n",
    "    return ai_laser_filter_bit * ai_laser_zstack_only\n",
    "\n",
    "ai_laser_filtered = filter_ai_laser(ai_laser, di_confocal, n_rec=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d263ab83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8156dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "ix2plot = slice(20000, 25000)\n",
    "plt.figure()\n",
    "plt.plot(ai_laser[ix2plot], label='Original AI Laser')\n",
    "plt.plot(ai_laser_filtered[ix2plot], label='Filtered AI Laser', alpha=0.7)\n",
    "# plt.plot(di_confocal[ix2plot], label='DI Confocal', alpha=0.5)\n",
    "plt.title('AI Laser and Filtered AI Laser Signals')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Signal Amplitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g5ht-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
