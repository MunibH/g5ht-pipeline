{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1b7a0b",
   "metadata": {},
   "source": [
    "### CONDA ENVIRONMENTS\n",
    "\n",
    "For steps __1. preprocess__ and __2. mip__, `conda activate g5ht-pipeline`\n",
    "\n",
    "For step __3. segment__, `conda activate segment-torch` or `conda activate torchcu129`\n",
    "\n",
    "For step __4. spline, 5. orient, 6. warp, 7. reg__\n",
    "\n",
    "## TODO:\n",
    "\n",
    "1. flip worms so that VNC is always up\n",
    "2. fixed mask could be automated, but if not, make sure to save which index is fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21220aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    import utils\n",
    "    is_torch_env = False\n",
    "except ImportError:\n",
    "    is_torch_env = True\n",
    "    print(\"utils not loaded because conda environment doesn't have nd2reader installed. probably using torchcu129 env, which is totally fine for just doing the segmentation step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a415d0",
   "metadata": {},
   "source": [
    "# SPECIFY DATA TO PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfdcf1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date-20251223_strain-ISg5HT_condition-starvedpatch_worm005.nd2\n",
      "Num z-slices:  41\n",
      "Number of frames:  1200\n",
      "Height:  512\n",
      "width:  512\n",
      "Number of channels:  2\n",
      "Beads alignment file:  C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251223\\date-20251223_strain-ISg5HT_condition-starvedpatch_worm005_chan_alignment.nd2\n"
     ]
    }
   ],
   "source": [
    "# DATA_PTH = r'C:\\Users\\munib\\POSTDOC\\DATA\\fluorescent_beads_ch_align\\20251219'\n",
    "DATA_PTH = r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251223'\n",
    "\n",
    "INPUT_ND2 = 'date-20251223_strain-ISg5HT_condition-starvedpatch_worm005.nd2'\n",
    "# INPUT_ND2 = 'date-20251223_strain-ISg5HT_condition-starvedpatch_worm005_chan_alignment.nd2'\n",
    "\n",
    "INPUT_ND2_PTH = os.path.join(DATA_PTH, INPUT_ND2)\n",
    "\n",
    "NOISE_PTH = r'C:\\Users\\munib\\POSTDOC\\CODE\\g5ht-pipeline\\noise\\noise_042925.tif'\n",
    "\n",
    "OUT_DIR = os.path.splitext(INPUT_ND2_PTH)[0]\n",
    "\n",
    "STACK_LENGTH = 41\n",
    "\n",
    "if not is_torch_env:\n",
    "    noise_stack = utils.get_noise_stack(NOISE_PTH, STACK_LENGTH)\n",
    "    num_frames, height, width, num_channels = utils.get_range_from_nd2(INPUT_ND2_PTH, stack_length=STACK_LENGTH) \n",
    "    beads_alignment_file = utils.get_beads_alignment_file(INPUT_ND2_PTH)\n",
    "else:\n",
    "    print(\"utils not loaded because conda environment doesn't have nd2reader installed. probably using torchcu129 env, which is totally fine for just doing the segmentation step\")\n",
    "\n",
    "print(INPUT_ND2)\n",
    "print('Num z-slices: ', STACK_LENGTH)\n",
    "if not is_torch_env:\n",
    "    print('Number of frames: ', num_frames)\n",
    "    print('Height: ', height)\n",
    "    print('width: ', width)\n",
    "    print('Number of channels: ', num_channels)\n",
    "    print('Beads alignment file: ', beads_alignment_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5702d46",
   "metadata": {},
   "source": [
    "# 0. PROCESS BEADS ALIGNMENT DATA (OPTIONAL, CHANGING THIS SO BEADS ARE PROCESSED SEAMLESSLY IN PIPELINE)\n",
    "\n",
    "` conda activate g5ht-pipeline`\n",
    "\n",
    "The registration parameters between green and red channels will be applied to worm recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d8333",
   "metadata": {},
   "source": [
    "### SHEAR CORRECT AND CHANNEL REGISTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a6273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_parallel import main as preprocess_nd2_parallel\n",
    "_ = importlib.reload(sys.modules['preprocess_parallel'])\n",
    "\n",
    "num_frames_beads, _, _, _ = utils.get_range_from_nd2(beads_alignment_file, stack_length=STACK_LENGTH) \n",
    "\n",
    "# # command-line arguments\n",
    "sys.argv = [\"\", beads_alignment_file, \"0\", str(num_frames_beads-1), NOISE_PTH, STACK_LENGTH, 5, num_frames_beads, height, width, num_channels]\n",
    "\n",
    "# # Call the main function\n",
    "preprocess_nd2_parallel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc57a3e8",
   "metadata": {},
   "source": [
    "### MIP\n",
    "\n",
    "This step saved the median channel registration parameters, need to do this somewhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7099cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mip import main as mip\n",
    "\n",
    "_ = importlib.reload(sys.modules['mip'])\n",
    "_ = importlib.reload(sys.modules['utils'])\n",
    "\n",
    "# command-line arguments\n",
    "sys.argv = [\"\", beads_alignment_file, STACK_LENGTH, num_frames_beads, 2]\n",
    "\n",
    "# Call the main function\n",
    "mip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d28b53",
   "metadata": {},
   "source": [
    "# 1. SHEAR CORRECTION\n",
    "\n",
    "` conda activate g5ht-pipeline`\n",
    "\n",
    "- shear corrects each volume\n",
    "  - depending on each exposure time, it can take roughly half a second between the first and last frames of a volume, so any movements need to be corrected for\n",
    "- creates one `.tif` for each volume and stores it in the `shear_corrected` directory\n",
    "\n",
    "##### TODO: should probably update stack length after shear correction since we cut it by 2, although not sure it's explicitly needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed7e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shear_correct\n",
    "_ = importlib.reload(sys.modules['shear_correct'])\n",
    "\n",
    "start_index = \"0\"\n",
    "cpu_count = str(int(os.cpu_count() / 2))\n",
    "\n",
    "# sys.argv = [\"\", nd2 file, start_frame, end_frame, noise_pth, stack_length, n_workers, num_frames, height, width, num_channels]\n",
    "sys.argv = [\"\", INPUT_ND2_PTH, start_index, str(num_frames-1), NOISE_PTH, STACK_LENGTH, cpu_count, num_frames, height, width, num_channels]\n",
    "\n",
    "# Call the main function\n",
    "shear_correct.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1357bd32",
   "metadata": {},
   "source": [
    "# 2. CHANNEL ALIGNMENT\n",
    "\n",
    "` conda activate g5ht-pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0617b",
   "metadata": {},
   "source": [
    "### 2a. GET MEDIAN CHANNEL ALIGNMENT PARAMETERS FROM ALL FRAMES\n",
    "\n",
    "- If channel alignment file found, uses that, if not uses worm recording\n",
    "- creates a `.txt` file for each volume that contains elastix channel registration parameters\n",
    "- creates `chan_align_params.csv` and  `chan_align.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e5cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "beads_alignment_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87844a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_channel_alignment\n",
    "import median_channel_alignment\n",
    "_ = importlib.reload(sys.modules['get_channel_alignment'])\n",
    "_ = importlib.reload(sys.modules['median_channel_alignment'])\n",
    "\n",
    "## set beads_alignment_file to None to use worm recording for channel alignment, even if beads file exists\n",
    "# beads_alignment_file = None\n",
    "\n",
    "start_index = \"0\"\n",
    "cpu_count = str(int(os.cpu_count() / 2))\n",
    "\n",
    "if beads_alignment_file is not None:\n",
    "    align_with_beads = True\n",
    "    num_frames_beads, _, _, _ = utils.get_range_from_nd2(beads_alignment_file, stack_length=STACK_LENGTH) \n",
    "    sys.argv = [\"\", beads_alignment_file, start_index, str(num_frames_beads-1), NOISE_PTH, STACK_LENGTH, cpu_count, num_frames_beads, height, width, num_channels, align_with_beads]\n",
    "else:\n",
    "    align_with_beads = False\n",
    "    sys.argv = [\"\", INPUT_ND2_PTH, start_index, str(num_frames-1), NOISE_PTH, STACK_LENGTH, cpu_count, num_frames, height, width, num_channels, align_with_beads]\n",
    "\n",
    "# # Call the main function\n",
    "get_channel_alignment.main()\n",
    "median_channel_alignment.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe582c3e",
   "metadata": {},
   "source": [
    "### 2b. APPLY MEDIAN CHANNEL ALIGNMENT PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b97453",
   "metadata": {},
   "source": [
    "- ouputs aligned volumes in `channel_aligned` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apply_channel_alignment\n",
    "_ = importlib.reload(sys.modules['apply_channel_alignment'])\n",
    "\n",
    "start_index = \"0800\"\n",
    "cpu_count = str(int(os.cpu_count() / 2))\n",
    "\n",
    "# 0786 to 0799 are bad frames in worm005.nd2, copied 0785 for each of those frames\n",
    "\n",
    "if beads_alignment_file is not None:\n",
    "    align_with_beads = True\n",
    "    num_frames_beads, _, _, _ = utils.get_range_from_nd2(beads_alignment_file, stack_length=STACK_LENGTH) \n",
    "    sys.argv = [\"\", INPUT_ND2_PTH, start_index, str(num_frames-1), NOISE_PTH, STACK_LENGTH, cpu_count, num_frames, height, width, num_channels, align_with_beads, beads_alignment_file]\n",
    "else:\n",
    "    align_with_beads = False\n",
    "    sys.argv = [\"\", INPUT_ND2_PTH, start_index, str(num_frames-1), NOISE_PTH, STACK_LENGTH, cpu_count, num_frames, height, width, num_channels, align_with_beads]\n",
    "\n",
    "\n",
    "# Call the main function\n",
    "apply_channel_alignment.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0aece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create copies of 0785 and rename it to 0786 to 0799\n",
    "# import shutil\n",
    "# for i in range(786, 800):\n",
    "#     shutil.copyfile(r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251223\\date-20251223_strain-ISg5HT_condition-starvedpatch_worm005\\channel_aligned\\0785.tif',\n",
    "#                     r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251223\\date-20251223_strain-ISg5HT_condition-starvedpatch_worm005\\channel_aligned\\{:04d}.tif'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdc706e",
   "metadata": {},
   "source": [
    "### 2c. PLOT CHANNEL ALIGNMENT PARAMETER DISTRIBUTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9193ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# make font sizes larger for visibility\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "out_dir = os.path.splitext(INPUT_ND2_PTH)[0]\n",
    "\n",
    "df = pd.read_csv(os.path.join(out_dir, 'chan_align_params.csv'))\n",
    "params = ['TransformParameter_0', 'TransformParameter_1', 'TransformParameter_2', 'TransformParameter_3', 'TransformParameter_4', 'TransformParameter_5']\n",
    "labels = ['Rx', 'Ry', 'Rz', 'Tx', 'Ty', 'Tz']\n",
    "\n",
    "# the xaxis limits for each subplot should be the same across figures\n",
    "\n",
    "xlims = np.zeros((6,2))\n",
    "\n",
    "plt.figure(figsize=(12,8), tight_layout=True)\n",
    "for i,param in enumerate(params):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.hist(df[param], bins=30, color='red', alpha=0.6)\n",
    "    # plot the median value as a vertical line\n",
    "    median_value = df[param].median()\n",
    "    plt.axvline(median_value, color='black', linestyle='dashed', linewidth=2)\n",
    "    plt.xlabel(labels[i])\n",
    "    plt.ylabel('Frequency')\n",
    "    # get xaxis limits\n",
    "    xlims[i,:] = plt.xlim()\n",
    "    # title is median value\n",
    "    plt.title(f'Median: {np.round(median_value,3)}', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "out_dir = os.path.splitext(INPUT_ND2_PTH)[0] + '_chan_alignment'\n",
    "df = pd.read_csv(os.path.join(out_dir, 'chan_align_params.csv'))\n",
    "params = ['TransformParameter_0', 'TransformParameter_1', 'TransformParameter_2', 'TransformParameter_3', 'TransformParameter_4', 'TransformParameter_5']\n",
    "labels = ['Rx', 'Ry', 'Rz', 'Tx', 'Ty', 'Tz']\n",
    "\n",
    "plt.figure(figsize=(12,8), tight_layout=True)\n",
    "for i,param in enumerate(params):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.hist(df[param], bins=30, color='blue', alpha=0.6)\n",
    "    # plot the median value as a vertical line\n",
    "    median_value = df[param].median()\n",
    "    plt.axvline(median_value, color='black', linestyle='dashed', linewidth=2)\n",
    "    plt.xlabel(labels[i])\n",
    "    plt.ylabel('Frequency')\n",
    "    # apply xlims\n",
    "    # plt.xlim(xlims[i,0], xlims[i,1])\n",
    "    # title is median value, font size 14\n",
    "    plt.title(f'Median: {np.round(median_value,3)}', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6189df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563861dd",
   "metadata": {},
   "source": [
    "# MIP\n",
    "\n",
    "` conda activate g5ht-pipeline`\n",
    "\n",
    "- outputs `focus.png`, `mip.tif`, and `mip.mp4`\n",
    "\n",
    "##### TODO: \n",
    "- legend for focus.png, should be frame#\n",
    "- mip for xy, xz, zy\n",
    "- mip for several slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mip\n",
    "\n",
    "_ = importlib.reload(sys.modules['mip'])\n",
    "_ = importlib.reload(sys.modules['utils'])\n",
    "\n",
    "# command-line arguments\n",
    "framerate = 10\n",
    "tif_dir = 'channel_aligned' # one of 'shear_corrected' 'channel_aligned'\n",
    "# tif_dir = 'channel_aligned_beads'\n",
    "rmax = 750\n",
    "gmax = 100\n",
    "mp4_quality = 5\n",
    "sys.argv = [\"\", INPUT_ND2_PTH, tif_dir, STACK_LENGTH, num_frames, framerate, rmax, gmax, mp4_quality]\n",
    "\n",
    "# Call the main function\n",
    "mip.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6588494",
   "metadata": {},
   "source": [
    "# 3. SEGMENT\n",
    "\n",
    "- outputs `label.tif`, contains segmented MIP for each volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f60d1",
   "metadata": {},
   "source": [
    "### on home pc\n",
    "`conda activate segment-torch`\n",
    "\n",
    "Uses a separate conda environment from the rest of the pipeline. create it using:\n",
    "`conda env create -f segment_torch.yml`\n",
    "\n",
    "### on lab pc\n",
    "`conda activate torchcu129`\n",
    "\n",
    "Uses a separate conda environment from the rest of the pipeline. create it following steps in:\n",
    "`segment_torch_cu129_environment.yml`\n",
    "\n",
    "### setup each time model weights change\n",
    "Need to set path to model weights as `CHECKPOINT` in `eval_torch.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92795d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segment.segment_torch\n",
    "_ = importlib.reload(sys.modules['segment.segment_torch'])\n",
    "\n",
    "MIP_PTH = os.path.join(os.path.splitext(INPUT_ND2_PTH)[0], 'mip_channel_aligned.tif')\n",
    "\n",
    "# command-line arguments\n",
    "sys.argv = [\"\", MIP_PTH]\n",
    "\n",
    "segment.segment_torch.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4989c725",
   "metadata": {},
   "source": [
    "# 4. SPLINE\n",
    "\n",
    "`conda activate g5ht-pipeline`\n",
    "\n",
    "- outputs `spline.json`, `spline.tif`, and `dilated.tif`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac034f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spline\n",
    "_ = importlib.reload(sys.modules['spline'])\n",
    "\n",
    "LABEL_PTH = MIP_PTH = os.path.join(os.path.splitext(INPUT_ND2_PTH)[0], 'label.tif')\n",
    "\n",
    "# command-line arguments\n",
    "sys.argv = [\"\", LABEL_PTH]\n",
    "\n",
    "spline.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fb7360",
   "metadata": {},
   "source": [
    "# 5. ORIENT\n",
    "\n",
    "`conda activate g5ht-pipeline`\n",
    "\n",
    "- outputs `oriented.json`, `oriented.png`, `oriented_stack.tif`\n",
    "\n",
    "NOTE: `orient_v2.py` automated the process of finding orientation completely, whereas `orient.py` requires you to input the (x,y) nose location on the first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orient_v2\n",
    "_ = importlib.reload(sys.modules['orient_v2'])\n",
    "\n",
    "SPLINE_PTH = MIP_PTH = os.path.join(os.path.splitext(INPUT_ND2_PTH)[0], 'spline.json')\n",
    "\n",
    "# command-line arguments\n",
    "sys.argv = [\"\", SPLINE_PTH]\n",
    "\n",
    "orient_v2.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb8bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orient\n",
    "_ = importlib.reload(sys.modules['orient'])\n",
    "\n",
    "SPLINE_PTH = MIP_PTH = os.path.join(os.path.splitext(INPUT_ND2_PTH)[0], 'spline.json')\n",
    "nose_y = 210\n",
    "nose_x = 9\n",
    "\n",
    "# command-line arguments\n",
    "sys.argv = [\"\", SPLINE_PTH, str(nose_y), str(nose_x)]\n",
    "\n",
    "orient.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae94ec6",
   "metadata": {},
   "source": [
    "# 6. WARP\n",
    "\n",
    "`conda activate g5ht-pipeline`\n",
    "\n",
    "- ouputs: `warped/*.tif` and `masks/*.tif`\n",
    "\n",
    "TODO: parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1eac07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 824/1200 [1:03:45<29:05,  4.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_30192\\451317464.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;28;01min\u001b[39;00m tqdm(range(num_frames)):\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# command-line arguments\u001b[39;00m\n\u001b[32m      8\u001b[39m     sys.argv = [\u001b[33m\"\"\u001b[39m, PTH, i]\n\u001b[32m      9\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     warp.main()\n",
      "\u001b[32mc:\\Users\\munib\\POSTDOC\\CODE\\g5ht-pipeline\\warp.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     73\u001b[39m     tifffile.imwrite(warped_tif_fn, warped, imagej=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     74\u001b[39m     \u001b[38;5;66;03m# print('Done warping stack!')\u001b[39;00m\n\u001b[32m     75\u001b[39m \n\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# load mask and warp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     dilated = tifffile.imread(os.path.join(out_dir, \u001b[33m'dilated.tif'\u001b[39m))\n\u001b[32m     78\u001b[39m     mask = dilated[index]\n\u001b[32m     79\u001b[39m     warped_mask = transform.warp(mask, tform, output_shape=(\u001b[32m200\u001b[39m, \u001b[32m500\u001b[39m), order=\u001b[32m0\u001b[39m)\n\u001b[32m     80\u001b[39m     os.makedirs(os.path.join(out_dir, \u001b[33m'masks'\u001b[39m), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32mc:\\Users\\munib\\miniconda3\\envs\\g5ht-pipeline\\Lib\\site-packages\\tifffile\\tifffile.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(files, selection, aszarr, key, series, level, squeeze, maxworkers, buffersize, mode, name, offset, size, pattern, axesorder, categories, imread, imreadargs, sort, container, chunkshape, chunkdtype, axestiled, ioworkers, chunkmode, fillvalue, zattrs, multiscales, omexml, superres, out, out_inplace, _multifile, _useframes, **kwargs)\u001b[39m\n\u001b[32m   1204\u001b[39m \n\u001b[32m   1205\u001b[39m                     \u001b[38;5;28;01mfrom\u001b[39;00m .zarr \u001b[38;5;28;01mimport\u001b[39;00m zarr_selection\n\u001b[32m   1206\u001b[39m \n\u001b[32m   1207\u001b[39m                     \u001b[38;5;28;01mreturn\u001b[39;00m zarr_selection(store, selection, out=out)\n\u001b[32m-> \u001b[39m\u001b[32m1208\u001b[39m                 return tif.asarray(\n\u001b[32m   1209\u001b[39m                     key=key,\n\u001b[32m   1210\u001b[39m                     series=series,\n\u001b[32m   1211\u001b[39m                     level=level,\n",
      "\u001b[32mc:\\Users\\munib\\miniconda3\\envs\\g5ht-pipeline\\Lib\\site-packages\\tifffile\\tifffile.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, series, level, squeeze, out, maxworkers, buffersize)\u001b[39m\n\u001b[32m   4531\u001b[39m             result = page0.asarray(\n\u001b[32m   4532\u001b[39m                 out=out, maxworkers=maxworkers, buffersize=buffersize\n\u001b[32m   4533\u001b[39m             )\n\u001b[32m   4534\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4535\u001b[39m             result = stack_pages(\n\u001b[32m   4536\u001b[39m                 pages, out=out, maxworkers=maxworkers, buffersize=buffersize\n\u001b[32m   4537\u001b[39m             )\n\u001b[32m   4538\u001b[39m \n",
      "\u001b[32mc:\\Users\\munib\\miniconda3\\envs\\g5ht-pipeline\\Lib\\site-packages\\tifffile\\tifffile.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(pages, tiled, lock, maxworkers, out, **kwargs)\u001b[39m\n\u001b[32m  21939\u001b[39m                 filecache.close(page.parent.filehandle)\n\u001b[32m  21940\u001b[39m \n\u001b[32m  21941\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m maxworkers < \u001b[32m2\u001b[39m:\n\u001b[32m  21942\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m index, page \u001b[38;5;28;01min\u001b[39;00m enumerate(pages):\n\u001b[32m> \u001b[39m\u001b[32m21943\u001b[39m                 func(page, index)\n\u001b[32m  21944\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m  21945\u001b[39m             page0.decode  \u001b[38;5;66;03m# init TiffPage.decode function\u001b[39;00m\n\u001b[32m  21946\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(maxworkers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n",
      "\u001b[32mc:\\Users\\munib\\miniconda3\\envs\\g5ht-pipeline\\Lib\\site-packages\\tifffile\\tifffile.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(page, index, out, filecache, kwargs)\u001b[39m\n\u001b[32m  21934\u001b[39m         ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m  21935\u001b[39m             \u001b[38;5;66;03m# read, decode, and copy page data\u001b[39;00m\n\u001b[32m  21936\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m page \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m  21937\u001b[39m                 filecache.open(page.parent.filehandle)\n\u001b[32m> \u001b[39m\u001b[32m21938\u001b[39m                 page.asarray(lock=lock, out=out[index], **kwargs)\n\u001b[32m  21939\u001b[39m                 filecache.close(page.parent.filehandle)\n",
      "\u001b[32mc:\\Users\\munib\\miniconda3\\envs\\g5ht-pipeline\\Lib\\site-packages\\tifffile\\tifffile.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m  10385\u001b[39m         Parameters:\n\u001b[32m  10386\u001b[39m             **kwargs: Arguments passed to :py:meth:`TiffPage.asarray`.\n\u001b[32m  10387\u001b[39m \n\u001b[32m  10388\u001b[39m         \"\"\"\n\u001b[32m> \u001b[39m\u001b[32m10389\u001b[39m         return TiffPage.asarray(\n\u001b[32m  10390\u001b[39m             self, *args, **kwargs  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m  10391\u001b[39m         )\n",
      "\u001b[32mc:\\Users\\munib\\miniconda3\\envs\\g5ht-pipeline\\Lib\\site-packages\\tifffile\\tifffile.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, out, squeeze, lock, maxworkers, buffersize)\u001b[39m\n\u001b[32m   8943\u001b[39m                 buffersize=buffersize,\n\u001b[32m   8944\u001b[39m                 sort=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   8945\u001b[39m                 _fullsize=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   8946\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m8947\u001b[39m                 \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   8948\u001b[39m \n\u001b[32m   8949\u001b[39m         result.shape = keyframe.shaped\n\u001b[32m   8950\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m squeeze:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import warp\n",
    "_ = importlib.reload(sys.modules['warp'])\n",
    "\n",
    "PTH = os.path.splitext(INPUT_ND2_PTH)[0]\n",
    "\n",
    "for i in tqdm(range(num_frames)):\n",
    "    # command-line arguments\n",
    "    sys.argv = [\"\", PTH, i]\n",
    "\n",
    "    warp.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2ddcbc",
   "metadata": {},
   "source": [
    "## 7. REGISTER\n",
    "\n",
    "`conda activate g5ht-pipeline`\n",
    "\n",
    "__ALTERNATIVELY__: register using the wholistic registration algorithm, currently in MATLAB\n",
    "\n",
    "TODO: parallelize / make faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b722e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "\n",
    "from reg import main as reg_worm\n",
    "\n",
    "\n",
    "PTH = r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251028\\date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm001_aligned'\n",
    "\n",
    "for i in tqdm(range(1200)):\n",
    "    # command-line arguments\n",
    "    sys.argv = [\"\", PTH, i, \"1\"]\n",
    "    reg_worm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd56099",
   "metadata": {},
   "source": [
    "### REGISTER WITH GFP+1 TO RFP\n",
    "\n",
    "TRIM LAST RFP ZSLICE, TRIM FIRST GFP ZSLICE\n",
    "\n",
    "seems to be that as of 20251204, all recordings were taken such that the i zslice in red channel corresponds to i+1 zslice in green channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d1eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "\n",
    "from reg_gfp_indexing import main as reg_worm\n",
    "\n",
    "PTH = r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251028\\date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm001_aligned'\n",
    "\n",
    "for i in tqdm(range(1200)):\n",
    "    # command-line arguments\n",
    "    sys.argv = [\"\", PTH, i, \"1\"]\n",
    "    reg_worm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8183d57b",
   "metadata": {},
   "source": [
    "### MAKE MOVIES OF REGISTERED DATA (see `reg_microfilm.ipynb`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4ebdbb",
   "metadata": {},
   "source": [
    "# 8. EXPORT DATA FOR ROI LABELING\n",
    "\n",
    "`conda activate g5ht-pipeline`\n",
    "\n",
    "- after this step, use `lbl` conda env to label ROI of fixed frame\n",
    "  - run `labelme` in terminal\n",
    "\n",
    "\n",
    "maybe also see here for video annotation: https://github.com/wkentaro/labelme/tree/main/examples/video_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c51b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code that exports each z-slice of fixed.tif as a separate png\n",
    "import tifffile\n",
    "import os\n",
    "import glob\n",
    "\n",
    "PTH = os.path.splitext(INPUT_ND2_PTH)[0]\n",
    "\n",
    "# in PTH directory, find a fixed_*.tif file, there is only one\n",
    "fixed_fn = glob.glob(os.path.join(PTH, 'fixed_*.tif'))[0]\n",
    "fixed_pth = os.path.join(PTH, fixed_fn)\n",
    "\n",
    "# fixed_pth = os.path.join(PTH, 'fixed.tif')\n",
    "fixed_stack = tifffile.imread(fixed_pth)\n",
    "\n",
    "out_dir = os.path.join(PTH, 'fixed_png')\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for i in range(fixed_stack.shape[0]):\n",
    "    slice_pth = os.path.join(out_dir, f'fixed_z{i:02d}.png')\n",
    "    # make sure to save channel 1, and that it is visible, correct data type, clipped to 0-255\n",
    "    slice_img = fixed_stack[i,1,:,:]\n",
    "    slice_img = (slice_img - slice_img.min()) / (slice_img.max() - slice_img.min()) * 255\n",
    "    slice_img = slice_img.astype('uint8')\n",
    "    tifffile.imwrite(slice_pth, slice_img) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5175c55",
   "metadata": {},
   "source": [
    "# 9. QUANTIFY\n",
    "\n",
    "`conda activate g5ht-pipeline`\n",
    "\n",
    "Have to first label dorsal and ventral nerve rings and pharynx. See ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebaed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import quantify\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 15}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "_ = importlib.reload(sys.modules['quantify'])\n",
    "\n",
    "PTH = r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251028\\date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm001_not_aligned'\n",
    "\n",
    "\n",
    "sys.argv = [\"\", PTH]\n",
    "quantify.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689526e2",
   "metadata": {},
   "source": [
    "#### EDIT PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c648d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_intensity = genfromtxt(os.path.join(PTH,'quantified.csv'), delimiter=',')\n",
    "roi_intensity = roi_intensity[1:,:]\n",
    "roi_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1836695",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "t = roi_intensity[:,0]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(t, roi_intensity[:, 1] / np.mean(roi_intensity[:60, 1]), label='Dorsal nerve ring', lw=3)\n",
    "plt.plot(t, roi_intensity[:, 2] / np.mean(roi_intensity[:60, 2]), label='Ventral nerve ring', lw=3)\n",
    "plt.plot(t, roi_intensity[:, 3] / np.mean(roi_intensity[:60, 3]), label='Pharynx', lw=3)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5)) \n",
    "plt.xlabel('Time (min)')\n",
    "plt.ylabel(r'$F/F_{baseline}$')\n",
    "plt.xlim(t[0],t[-1])\n",
    "plt.axhline(1, ls='--', c='k', zorder=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856532c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf37106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fe9c630",
   "metadata": {},
   "source": [
    "# OLD PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede127a7",
   "metadata": {},
   "source": [
    "## 1. PREPROCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9222cd98",
   "metadata": {},
   "source": [
    "### PARALLEL\n",
    "\n",
    "if processing locally, would recommend setting the 6th arg (number of workers) to something less than 10 if you want to use your computer at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d5463",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- make a new step 2, that is 'align channels'\n",
    "- it should first look for a beads .nd2, if not falls back to previous method\n",
    "- alternatively, in the case of not aligning with beads, preprocess should do the median parameters and apply them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca70622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_parallel import main as preprocess_nd2_parallel\n",
    "_ = importlib.reload(sys.modules['preprocess_parallel'])\n",
    "\n",
    "# command-line arguments\n",
    "# sys.argv = [\"\", INPUT_ND2_PTH, \"0\", str(num_frames), NOISE_PTH, STACK_LENGTH, 5]\n",
    "\n",
    "# if not None:\n",
    "#     align_with_beads = True # set to true when processing a worm recording with beads that have already been processed\n",
    "# else:\n",
    "#     align_with_beads = False\n",
    "align_with_beads = True\n",
    "# sys.argv = [\"\", INPUT_ND2_PTH, \"1068\", str(num_frames-1), NOISE_PTH, STACK_LENGTH, 5, num_frames, height, width, num_channels, align_with_beads]\n",
    "sys.argv = [\"\", INPUT_ND2_PTH, \"1090\", \"1094\", NOISE_PTH, STACK_LENGTH, 5, num_frames, height, width, num_channels, align_with_beads]\n",
    "\n",
    "# Call the main function\n",
    "preprocess_nd2_parallel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d489d",
   "metadata": {},
   "source": [
    "### SERIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2346ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import main as preprocess_nd2\n",
    "_ = importlib.reload(sys.modules['utils'])\n",
    "\n",
    "# command-line arguments\n",
    "# sys.argv = [\"\", INPUT_ND2_PTH, \"0\", NOISE_PTH]\n",
    "sys.argv = [\"\", INPUT_ND2_PTH, \"0\", NOISE_PTH, STACK_LENGTH, num_frames, height, width, num_channels]\n",
    "\n",
    "# Call the main function\n",
    "preprocess_nd2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12fd6e",
   "metadata": {},
   "source": [
    "## 2. MAX INTENSITY PROJECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f8ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mip import main as mip\n",
    "\n",
    "_ = importlib.reload(sys.modules['mip'])\n",
    "_ = importlib.reload(sys.modules['utils'])\n",
    "\n",
    "# command-line arguments\n",
    "sys.argv = [\"\", INPUT_ND2_PTH, STACK_LENGTH, num_frames, 10]\n",
    "\n",
    "# Call the main function\n",
    "mip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f81d61f",
   "metadata": {},
   "source": [
    "## 3. SEGMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e6016c",
   "metadata": {},
   "source": [
    "### on home pc\n",
    "`conda activate segment-torch`\n",
    "\n",
    "Uses a separate conda environment from the rest of the pipeline. create it using:\n",
    "`conda env create -f segment_torch.yml`\n",
    "\n",
    "### on lab pc\n",
    "`conda activate torchcu129`\n",
    "\n",
    "Uses a separate conda environment from the rest of the pipeline. create it following steps in:\n",
    "`segment_torch_cu129_environment.yml`\n",
    "\n",
    "### setup each time model weights change\n",
    "Need to set path to model weights as `CHECKPOINT` in `eval_torch.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3ceed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "DATA_PTH = r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251028\\date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm001_aligned'\n",
    "INPUT_ND2 = 'date-20251121_strain-ISg5HT_condition-fedpatch_worm002.nd2'\n",
    "INPUT_ND2_PTH = os.path.join(DATA_PTH, INPUT_ND2)\n",
    "OUT_DIR = os.path.splitext(INPUT_ND2_PTH)[0]\n",
    "MIP_PTH = os.path.join(DATA_PTH, 'mip.tif')\n",
    "\n",
    "OUT_DIR = os.path.splitext(INPUT_ND2_PTH)[0]\n",
    "\n",
    "STACK_LENGTH = 15\n",
    "\n",
    "print(INPUT_ND2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae944bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment.segment_torch import main as segment_mip\n",
    "\n",
    "\n",
    "# command-line arguments\n",
    "sys.argv = [\"\", MIP_PTH]\n",
    "\n",
    "segment_mip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c843f8",
   "metadata": {},
   "source": [
    "## 4. SPLINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e5533a",
   "metadata": {},
   "source": [
    "`conda activate g5ht-pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from spline import main as get_spline\n",
    "\n",
    "# PTH = r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251028\\date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm001\\label.tif'\n",
    "PTH = r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251121\\date-20251121_strain-ISg5HT_condition-fedpatch_worm002\\label.tif'\n",
    "\n",
    "# command-line arguments\n",
    "sys.argv = [\"\", PTH]\n",
    "\n",
    "get_spline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d126e2",
   "metadata": {},
   "source": [
    "## 5. ORIENT\n",
    "\n",
    "`conda activate g5ht-pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f917129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from orient import main as find_orientation\n",
    "\n",
    "# PTH = r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251028\\date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm001\\spline.json'\n",
    "PTH = r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251121\\date-20251121_strain-ISg5HT_condition-fedpatch_worm002\\spline.json'\n",
    "\n",
    "# command-line arguments\n",
    "sys.argv = [\"\", PTH, 108, 42]\n",
    "\n",
    "find_orientation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a41ef3c",
   "metadata": {},
   "source": [
    "## 6. WARP\n",
    "\n",
    "`conda activate g5ht-pipeline`\n",
    "\n",
    "TODO: parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd6162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from warp import main as warp_worm\n",
    "from tqdm import tqdm\n",
    "from utils import get_range_from_nd2\n",
    "\n",
    "\n",
    "DATA_PTH = r\"C:\\\\Users\\\\munib\\\\POSTDOC\\\\DATA\\\\g5ht-free\\\\20251028\\\\\"\n",
    "INPUT_ND2 = 'date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm001_aligned.nd2'\n",
    "INPUT_ND2_PTH = os.path.join(DATA_PTH, INPUT_ND2)\n",
    "STACK_LENGTH = 41\n",
    "num_frames, height, width, num_channels = get_range_from_nd2(INPUT_ND2_PTH, stack_length=STACK_LENGTH) \n",
    "\n",
    "# PTH = r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251121\\date-20251121_strain-ISg5HT_condition-fedpatch_worm002'\n",
    "PTH = os.path.join(DATA_PTH,os.path.splitext(INPUT_ND2)[0])\n",
    "\n",
    "for i in tqdm(range(num_frames)):\n",
    "    # command-line arguments\n",
    "    sys.argv = [\"\", PTH, i]\n",
    "\n",
    "    warp_worm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06389982",
   "metadata": {},
   "source": [
    "### TEST PARALLEL (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c81b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warp_parallel import main as warp_worm_parallel\n",
    "\n",
    "PTH = r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251028\\date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm001'\n",
    "\n",
    "# command-line arguments\n",
    "sys.argv = [\"\", PTH, \"0\", \"1199\"]\n",
    "\n",
    "# Call the main function\n",
    "warp_worm_parallel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db573f6",
   "metadata": {},
   "source": [
    "## 7. REG\n",
    "\n",
    "`conda activate g5ht-pipeline`\n",
    "\n",
    "TODO: parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84531682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "\n",
    "from reg import main as reg_worm\n",
    "\n",
    "\n",
    "PTH = r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251028\\date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm001_aligned'\n",
    "\n",
    "for i in tqdm(range(1200)):\n",
    "    # command-line arguments\n",
    "    sys.argv = [\"\", PTH, i, \"1\"]\n",
    "    reg_worm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7a8674",
   "metadata": {},
   "source": [
    "### REGISTER WITH GFP+1 TO RFP\n",
    "\n",
    "TRIM LAST RFP ZSLICE, TRIM FIRST GFP ZSLICE\n",
    "\n",
    "seems to be that as of 20251204, all recordings were taken such that the i zslice in red channel corresponds to i+1 zslice in green channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d141790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "\n",
    "from reg_gfp_indexing import main as reg_worm\n",
    "\n",
    "PTH = r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251028\\date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm001_aligned'\n",
    "\n",
    "for i in tqdm(range(1200)):\n",
    "    # command-line arguments\n",
    "    sys.argv = [\"\", PTH, i, \"1\"]\n",
    "    reg_worm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a31ae9",
   "metadata": {},
   "source": [
    "### View fixed and move as one image (see reg_microfilm.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a785506",
   "metadata": {},
   "source": [
    "## 8. QUANTIFY\n",
    "\n",
    "`conda activate g5ht-pipeline`\n",
    "\n",
    "Have to first label dorsal and ventral nerve rings and pharynx. See ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b5eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from quantify import main as quantify_roi_intensity\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 15}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "PTH = r'C:\\Users\\munib\\POSTDOC\\DATA\\g5ht-free\\20251028\\date-20251028_time-1500_strain-ISg5HT_condition-starvedpatch_worm001_not_aligned'\n",
    "\n",
    "\n",
    "sys.argv = [\"\", PTH]\n",
    "quantify_roi_intensity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a23396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_intensity = genfromtxt(os.path.join(PTH,'quantified.csv'), delimiter=',')\n",
    "roi_intensity = roi_intensity[1:,:]\n",
    "roi_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757e12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "t = roi_intensity[:,0]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(t, roi_intensity[:, 1] / np.mean(roi_intensity[:60, 1]), label='Dorsal nerve ring', lw=3)\n",
    "plt.plot(t, roi_intensity[:, 2] / np.mean(roi_intensity[:60, 2]), label='Ventral nerve ring', lw=3)\n",
    "plt.plot(t, roi_intensity[:, 3] / np.mean(roi_intensity[:60, 3]), label='Pharynx', lw=3)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5)) \n",
    "plt.xlabel('Time (min)')\n",
    "plt.ylabel(r'$F/F_{baseline}$')\n",
    "plt.xlim(t[0],t[-1])\n",
    "plt.axhline(1, ls='--', c='k', zorder=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b956a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g5ht-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
